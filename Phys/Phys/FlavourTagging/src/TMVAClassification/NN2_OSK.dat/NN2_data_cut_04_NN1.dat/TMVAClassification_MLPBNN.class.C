// Class: ReadMLPBNN
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLPBNN
TMVA Release   : 4.1.3         [262403]
ROOT Release   : 5.30/04       [335364]
Creator        : kreplin
Date           : Wed Jan  9 18:14:57 2013
Host           : Linux lxbuild148.cern.ch 2.6.18-194.26.1.el5 #1 SMP Wed Nov 10 09:45:46 CET 2010 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /auto/sigma0/work2/kreplin/TMVA-v4.1.2/test
Training events: 90000
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
NCycles: "600" [Number of training cycles]
HiddenLayers: "N+8" [Specification of hidden layer architecture]
NeuronType: "sigmoid" [Neuron activation function type]
EstimatorType: "CE" [MSE (Mean Square Estimator) for Gaussian Likelihood or CE(Cross-Entropy) for Bernoulli Likelihood]
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
VarTransform: "N,D" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
H: "True" [Print method-specific help message]
TrainingMethod: "BFGS" [Train with Back-Propagation (BP), BFGS Algorithm (BFGS), or Genetic Algorithm (GA - slower and worse)]
TestRate: "5" [Test for overtraining performed at each #th epochs]
UseRegulator: "True" [Use regulator to avoid over-training]
CalculateErrors: "True" [Calculates inverse Hessian matrix at the end of the training to be able to calculate the uncertainties of an MVA value]
# Default:
RandomSeed: "1" [Random seed for initial synapse weights (0 means unique seed for each run; default value '1')]
NeuronInputType: "sum" [Neuron input function type]
VerbosityLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
LearningRate: "2.000000e-02" [ANN learning rate parameter]
DecayRate: "1.000000e-02" [Decay rate for learning parameter]
EpochMonitoring: "False" [Provide epoch-wise monitoring plots according to TestRate (caution: causes big ROOT output file!)]
Sampling: "1.000000e+00" [Only 'Sampling' (randomly selected) events are trained each epoch]
SamplingEpoch: "1.000000e+00" [Sampling is used for the first 'SamplingEpoch' epochs, afterwards, all events are taken for training]
SamplingImportance: "1.000000e+00" [ The sampling weights of events in epochs which successful (worse estimator than before) are multiplied with SamplingImportance, else they are divided.]
SamplingTraining: "True" [The training sample is sampled]
SamplingTesting: "False" [The testing sample is sampled]
ResetStep: "50" [How often BFGS should reset history]
Tau: "3.000000e+00" [LineSearch "size step"]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
ConvergenceImprove: "1.000000e-30" [Minimum improvement which counts as improvement (<0 means automatic convergence check is turned off)]
ConvergenceTests: "-1" [Number of steps (without improvement) required for convergence (<0 means automatic convergence check is turned off)]
UpdateLimit: "10000" [Maximum times of regulator update]
WeightRange: "1.000000e+00" [Take the events for the estimator calculations from small deviations from the desired value to large deviations only over the weight range]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 11
sign_tag[0]*rnet_opp[0]       sign_tag_0__T_rnet_opp_0_     sign_tag[0]*rnet_opp[0]       sign_tag[0]*rnet_opp[0]       units                             'F'    [-0.998661220074,0.997019350529]
sign_tag[1]*rnet_opp[1]       sign_tag_1__T_rnet_opp_1_     sign_tag[1]*rnet_opp[1]       sign_tag[1]*rnet_opp[1]       units                             'F'    [-0.99699151516,0.994016289711]
sign_tag[2]*rnet_opp[2]       sign_tag_2__T_rnet_opp_2_     sign_tag[2]*rnet_opp[2]       sign_tag[2]*rnet_opp[2]       units                             'F'    [-0.985854327679,0.993785560131]
sign_tag[3]*rnet_opp[3]       sign_tag_3__T_rnet_opp_3_     sign_tag[3]*rnet_opp[3]       sign_tag[3]*rnet_opp[3]       units                             'F'    [-0.968796253204,0.983174741268]
sign_tag[0]*pidk[0]           sign_tag_0__T_pidk_0_         sign_tag[0]*pidk[0]           sign_tag[0]*pidk[0]           units                             'F'    [-130.405899048,118.504402161]
sign_tag[1]*pidk[1]           sign_tag_1__T_pidk_1_         sign_tag[1]*pidk[1]           sign_tag[1]*pidk[1]           units                             'F'    [-117.963996887,125.757499695]
sign_tag[2]*pidk[2]           sign_tag_2__T_pidk_2_         sign_tag[2]*pidk[2]           sign_tag[2]*pidk[2]           units                             'F'    [-109.9036026,98.1610031128]
sign_tag[3]*pidk[3]           sign_tag_3__T_pidk_3_         sign_tag[3]*pidk[3]           sign_tag[3]*pidk[3]           units                             'F'    [-95.6821975708,95.491897583]
B_pt                          B_pt                          B_pt                          B_pt                          units                             'F'    [12.2331514359,79008.6171875]
no_vtx                        no_vtx                        no_vtx                        no_vtx                        units                             'I'    [1,9]
cands                         cands                         cands                         cands                         units                             'I'    [1,11]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadMLPBNN : public IClassifierReader {

 public:

   // constructor
   ReadMLPBNN( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLPBNN" ),
        fNvars( 11 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "sign_tag[0]*rnet_opp[0]", "sign_tag[1]*rnet_opp[1]", "sign_tag[2]*rnet_opp[2]", "sign_tag[3]*rnet_opp[3]", "sign_tag[0]*pidk[0]", "sign_tag[1]*pidk[1]", "sign_tag[2]*pidk[2]", "sign_tag[3]*pidk[3]", "B_pt", "no_vtx", "cands" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = -1.66247880458832;
      fVmax[0] = 1.5445739030838;
      fVmin[1] = -2.39292025566101;
      fVmax[1] = 2.55483460426331;
      fVmin[2] = -4.10796356201172;
      fVmax[2] = 3.71611070632935;
      fVmin[3] = -6.63456964492798;
      fVmax[3] = 6.10569953918457;
      fVmin[4] = -7.23989772796631;
      fVmax[4] = 7.93647432327271;
      fVmin[5] = -9.81583595275879;
      fVmax[5] = 8.93817138671875;
      fVmin[6] = -12.1400623321533;
      fVmax[6] = 11.4306116104126;
      fVmin[7] = -16.6930179595947;
      fVmax[7] = 16.3852310180664;
      fVmin[8] = -9.10544776916504;
      fVmax[8] = 8.99176502227783;
      fVmin[9] = -4.71063423156738;
      fVmax[9] = 3.97929644584656;
      fVmin[10] = -4.57873392105103;
      fVmax[10] = 3.84393525123596;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'I';
      fType[10] = 'I';

      // initialize constants
      Initialize();

      // initialize transformation
      InitTransform();
   }

   // destructor
   virtual ~ReadMLPBNN() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // input variable transformation

   double fMin_1[3][11];
   double fMax_1[3][11];

   double fDecTF_2[3][11][11];
   void InitTransform_1();
   void Transform_1( std::vector<double> & iv, int sigOrBgd ) const;
   void InitTransform_2();
   void Transform_2( std::vector<double> & iv, int sigOrBgd ) const;
   void InitTransform();
   void Transform( std::vector<double> & iv, int sigOrBgd ) const;

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[11];
   double fVmax[11];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[11];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;
   double OutputActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[3];
   double fWeightMatrix0to1[20][12];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[1][20];   // weight matrix from layer 1 to 2

   double * fWeights[3];
};

inline void ReadMLPBNN::Initialize()
{
   // build network structure
   fLayers = 3;
   fLayerSize[0] = 12; fWeights[0] = new double[12]; 
   fLayerSize[1] = 20; fWeights[1] = new double[20]; 
   fLayerSize[2] = 1; fWeights[2] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.516006404898333;
   fWeightMatrix0to1[1][0] = 2.90378028727485;
   fWeightMatrix0to1[2][0] = 0.0989108585302781;
   fWeightMatrix0to1[3][0] = 1.76800767611846;
   fWeightMatrix0to1[4][0] = -0.875420082627659;
   fWeightMatrix0to1[5][0] = -0.94993135751145;
   fWeightMatrix0to1[6][0] = -0.746328976630175;
   fWeightMatrix0to1[7][0] = 1.48313220475519;
   fWeightMatrix0to1[8][0] = -5.44564488572472;
   fWeightMatrix0to1[9][0] = -3.57235550445401;
   fWeightMatrix0to1[10][0] = -1.37363463738984;
   fWeightMatrix0to1[11][0] = -0.406946552799262;
   fWeightMatrix0to1[12][0] = -1.15621198744732;
   fWeightMatrix0to1[13][0] = 0.112358166201014;
   fWeightMatrix0to1[14][0] = -0.333008642588464;
   fWeightMatrix0to1[15][0] = 0.4676814599466;
   fWeightMatrix0to1[16][0] = -0.244228671429131;
   fWeightMatrix0to1[17][0] = 1.42559389328167;
   fWeightMatrix0to1[18][0] = 0.225160556985473;
   fWeightMatrix0to1[0][1] = 0.797007286749087;
   fWeightMatrix0to1[1][1] = 0.203994280417213;
   fWeightMatrix0to1[2][1] = -0.45199221338876;
   fWeightMatrix0to1[3][1] = 0.500616509185163;
   fWeightMatrix0to1[4][1] = 0.769515141350314;
   fWeightMatrix0to1[5][1] = -0.89793081416452;
   fWeightMatrix0to1[6][1] = -0.0262172410389299;
   fWeightMatrix0to1[7][1] = 1.05038333997326;
   fWeightMatrix0to1[8][1] = -0.319906189017503;
   fWeightMatrix0to1[9][1] = -0.355257164504086;
   fWeightMatrix0to1[10][1] = -0.0254794090946033;
   fWeightMatrix0to1[11][1] = 0.186087647472466;
   fWeightMatrix0to1[12][1] = 1.1506581295155;
   fWeightMatrix0to1[13][1] = -0.395308771513934;
   fWeightMatrix0to1[14][1] = -0.125365932310796;
   fWeightMatrix0to1[15][1] = 0.490824697441893;
   fWeightMatrix0to1[16][1] = -0.192938295816463;
   fWeightMatrix0to1[17][1] = -1.45293570127572;
   fWeightMatrix0to1[18][1] = 1.15904710211748;
   fWeightMatrix0to1[0][2] = -1.42378283174911;
   fWeightMatrix0to1[1][2] = 0.236672438360907;
   fWeightMatrix0to1[2][2] = 0.626718371835941;
   fWeightMatrix0to1[3][2] = 0.454211343102007;
   fWeightMatrix0to1[4][2] = 1.36507393037473;
   fWeightMatrix0to1[5][2] = 0.930781478978514;
   fWeightMatrix0to1[6][2] = -0.65253502061006;
   fWeightMatrix0to1[7][2] = -1.01799686941117;
   fWeightMatrix0to1[8][2] = 0.0239373692487909;
   fWeightMatrix0to1[9][2] = -0.0958325686259982;
   fWeightMatrix0to1[10][2] = 1.10714954473102;
   fWeightMatrix0to1[11][2] = 0.886939534045843;
   fWeightMatrix0to1[12][2] = 1.4668679015886;
   fWeightMatrix0to1[13][2] = 1.54691018593624;
   fWeightMatrix0to1[14][2] = -1.30411837657327;
   fWeightMatrix0to1[15][2] = 0.899848095952111;
   fWeightMatrix0to1[16][2] = -1.21285291079053;
   fWeightMatrix0to1[17][2] = -1.29950842260312;
   fWeightMatrix0to1[18][2] = -0.950233566260198;
   fWeightMatrix0to1[0][3] = -1.04746298729132;
   fWeightMatrix0to1[1][3] = -0.243822262988572;
   fWeightMatrix0to1[2][3] = 0.290133909760579;
   fWeightMatrix0to1[3][3] = -1.34276258293956;
   fWeightMatrix0to1[4][3] = 0.275376795630385;
   fWeightMatrix0to1[5][3] = -0.241042385117076;
   fWeightMatrix0to1[6][3] = 0.221252072905436;
   fWeightMatrix0to1[7][3] = 1.38400590464614;
   fWeightMatrix0to1[8][3] = -0.0876733842273248;
   fWeightMatrix0to1[9][3] = 0.00083901902960995;
   fWeightMatrix0to1[10][3] = -0.654971623651205;
   fWeightMatrix0to1[11][3] = 0.368572098759361;
   fWeightMatrix0to1[12][3] = -0.464195308360579;
   fWeightMatrix0to1[13][3] = -0.505863151206372;
   fWeightMatrix0to1[14][3] = -0.633770074887088;
   fWeightMatrix0to1[15][3] = 0.786388031685251;
   fWeightMatrix0to1[16][3] = 0.666117561431471;
   fWeightMatrix0to1[17][3] = 0.454401497379889;
   fWeightMatrix0to1[18][3] = -0.149880478814113;
   fWeightMatrix0to1[0][4] = -1.44228867510364;
   fWeightMatrix0to1[1][4] = -0.845202033680312;
   fWeightMatrix0to1[2][4] = 0.26336213745683;
   fWeightMatrix0to1[3][4] = -0.00553455885380902;
   fWeightMatrix0to1[4][4] = 2.40219497752481;
   fWeightMatrix0to1[5][4] = 0.512340449311175;
   fWeightMatrix0to1[6][4] = 0.724258181332187;
   fWeightMatrix0to1[7][4] = -0.380931215900716;
   fWeightMatrix0to1[8][4] = -1.30918419507168;
   fWeightMatrix0to1[9][4] = -0.911560019291127;
   fWeightMatrix0to1[10][4] = 0.929462466632915;
   fWeightMatrix0to1[11][4] = -0.769017664246207;
   fWeightMatrix0to1[12][4] = -1.02340333241618;
   fWeightMatrix0to1[13][4] = -1.13627222237645;
   fWeightMatrix0to1[14][4] = -0.238641725290466;
   fWeightMatrix0to1[15][4] = 0.125633219872144;
   fWeightMatrix0to1[16][4] = 1.43503171050438;
   fWeightMatrix0to1[17][4] = -0.765294434607476;
   fWeightMatrix0to1[18][4] = -0.663775169200403;
   fWeightMatrix0to1[0][5] = 1.07346592923142;
   fWeightMatrix0to1[1][5] = -0.53807438716713;
   fWeightMatrix0to1[2][5] = -0.959420499415877;
   fWeightMatrix0to1[3][5] = -0.800173560885133;
   fWeightMatrix0to1[4][5] = 0.622706810955009;
   fWeightMatrix0to1[5][5] = -1.05554435094833;
   fWeightMatrix0to1[6][5] = -1.07182893835672;
   fWeightMatrix0to1[7][5] = 0.42538473739904;
   fWeightMatrix0to1[8][5] = -0.08008647057036;
   fWeightMatrix0to1[9][5] = -0.0536203444184439;
   fWeightMatrix0to1[10][5] = 1.07795656903545;
   fWeightMatrix0to1[11][5] = -0.572155050529109;
   fWeightMatrix0to1[12][5] = -0.442240708425494;
   fWeightMatrix0to1[13][5] = 0.225513776668107;
   fWeightMatrix0to1[14][5] = 0.344761661656782;
   fWeightMatrix0to1[15][5] = -1.28625139981749;
   fWeightMatrix0to1[16][5] = 0.216037838022568;
   fWeightMatrix0to1[17][5] = 0.415444361914139;
   fWeightMatrix0to1[18][5] = 0.318877337836766;
   fWeightMatrix0to1[0][6] = -1.3328915732648;
   fWeightMatrix0to1[1][6] = 2.29240243616081;
   fWeightMatrix0to1[2][6] = 0.120943481394136;
   fWeightMatrix0to1[3][6] = -0.461794125437861;
   fWeightMatrix0to1[4][6] = 0.13475814790361;
   fWeightMatrix0to1[5][6] = -0.689378741628627;
   fWeightMatrix0to1[6][6] = -0.562596905573463;
   fWeightMatrix0to1[7][6] = -0.208952914241974;
   fWeightMatrix0to1[8][6] = -0.0572825424080016;
   fWeightMatrix0to1[9][6] = -0.0181467700034878;
   fWeightMatrix0to1[10][6] = 0.329548175312931;
   fWeightMatrix0to1[11][6] = 0.188793931833274;
   fWeightMatrix0to1[12][6] = -0.406567966761393;
   fWeightMatrix0to1[13][6] = 0.19628319471933;
   fWeightMatrix0to1[14][6] = -1.13444120121593;
   fWeightMatrix0to1[15][6] = 0.618441435965812;
   fWeightMatrix0to1[16][6] = -0.080564489276374;
   fWeightMatrix0to1[17][6] = -0.201080055703084;
   fWeightMatrix0to1[18][6] = 0.326334516049795;
   fWeightMatrix0to1[0][7] = -0.599096886707919;
   fWeightMatrix0to1[1][7] = -0.663709574646123;
   fWeightMatrix0to1[2][7] = 0.835766032506396;
   fWeightMatrix0to1[3][7] = 1.3429775997763;
   fWeightMatrix0to1[4][7] = -0.543799634826152;
   fWeightMatrix0to1[5][7] = 0.180270445925235;
   fWeightMatrix0to1[6][7] = 0.717737424917297;
   fWeightMatrix0to1[7][7] = 0.820636942392529;
   fWeightMatrix0to1[8][7] = -0.120209568102327;
   fWeightMatrix0to1[9][7] = -0.196436623392653;
   fWeightMatrix0to1[10][7] = 0.0178109599777432;
   fWeightMatrix0to1[11][7] = -1.15112702528043;
   fWeightMatrix0to1[12][7] = 0.655641636509438;
   fWeightMatrix0to1[13][7] = 0.576410823610063;
   fWeightMatrix0to1[14][7] = -0.290623407330341;
   fWeightMatrix0to1[15][7] = -0.156303055931113;
   fWeightMatrix0to1[16][7] = 0.0482505315938237;
   fWeightMatrix0to1[17][7] = -1.64403009554232;
   fWeightMatrix0to1[18][7] = 0.201887405561408;
   fWeightMatrix0to1[0][8] = 1.84154713854184;
   fWeightMatrix0to1[1][8] = -0.100165916907849;
   fWeightMatrix0to1[2][8] = 2.20633846524699;
   fWeightMatrix0to1[3][8] = -0.207852388628796;
   fWeightMatrix0to1[4][8] = 0.876992388774385;
   fWeightMatrix0to1[5][8] = 2.06068203276584;
   fWeightMatrix0to1[6][8] = -2.03852359240769;
   fWeightMatrix0to1[7][8] = -2.7384772733169;
   fWeightMatrix0to1[8][8] = 0.40908152572578;
   fWeightMatrix0to1[9][8] = -0.169600104957455;
   fWeightMatrix0to1[10][8] = 1.5610186075319;
   fWeightMatrix0to1[11][8] = 0.90612606400723;
   fWeightMatrix0to1[12][8] = 2.75695393087377;
   fWeightMatrix0to1[13][8] = -0.0840795472895635;
   fWeightMatrix0to1[14][8] = 2.04192810886989;
   fWeightMatrix0to1[15][8] = 1.6775120546373;
   fWeightMatrix0to1[16][8] = 1.46129193729555;
   fWeightMatrix0to1[17][8] = -0.602598060575662;
   fWeightMatrix0to1[18][8] = 1.60570120309968;
   fWeightMatrix0to1[0][9] = 1.59294190847644;
   fWeightMatrix0to1[1][9] = 0.547563935328586;
   fWeightMatrix0to1[2][9] = 2.37238290703063;
   fWeightMatrix0to1[3][9] = 1.75915933563609;
   fWeightMatrix0to1[4][9] = -1.64984042065277;
   fWeightMatrix0to1[5][9] = 1.11244129140104;
   fWeightMatrix0to1[6][9] = -1.22113241834996;
   fWeightMatrix0to1[7][9] = -0.491637404702865;
   fWeightMatrix0to1[8][9] = 0.0927586587731091;
   fWeightMatrix0to1[9][9] = -0.376455013029065;
   fWeightMatrix0to1[10][9] = 1.33332769244872;
   fWeightMatrix0to1[11][9] = 1.70022727621179;
   fWeightMatrix0to1[12][9] = -0.821767003620286;
   fWeightMatrix0to1[13][9] = -0.360317083735419;
   fWeightMatrix0to1[14][9] = 0.738024048274658;
   fWeightMatrix0to1[15][9] = 0.94880322486098;
   fWeightMatrix0to1[16][9] = 2.07598741312366;
   fWeightMatrix0to1[17][9] = -0.638454838321077;
   fWeightMatrix0to1[18][9] = 0.0134114939389307;
   fWeightMatrix0to1[0][10] = -0.413254676846922;
   fWeightMatrix0to1[1][10] = 0.212006736511166;
   fWeightMatrix0to1[2][10] = 2.40247655291399;
   fWeightMatrix0to1[3][10] = 0.175670082740674;
   fWeightMatrix0to1[4][10] = 0.15930420852256;
   fWeightMatrix0to1[5][10] = -0.0472328344570448;
   fWeightMatrix0to1[6][10] = -2.36896697797248;
   fWeightMatrix0to1[7][10] = 0.495554916977126;
   fWeightMatrix0to1[8][10] = 0.220276160605297;
   fWeightMatrix0to1[9][10] = -0.0347581733333382;
   fWeightMatrix0to1[10][10] = -0.287247228743479;
   fWeightMatrix0to1[11][10] = 0.432555990514724;
   fWeightMatrix0to1[12][10] = 0.675729113960003;
   fWeightMatrix0to1[13][10] = -1.74871491159234;
   fWeightMatrix0to1[14][10] = 2.17505913529362;
   fWeightMatrix0to1[15][10] = 1.07338824623212;
   fWeightMatrix0to1[16][10] = 0.29181745135976;
   fWeightMatrix0to1[17][10] = -0.296102743212729;
   fWeightMatrix0to1[18][10] = 1.55192323566837;
   fWeightMatrix0to1[0][11] = 0.780820352086125;
   fWeightMatrix0to1[1][11] = 0.613002583723708;
   fWeightMatrix0to1[2][11] = -0.451823208396729;
   fWeightMatrix0to1[3][11] = -1.67110289811932;
   fWeightMatrix0to1[4][11] = -0.784436489173227;
   fWeightMatrix0to1[5][11] = 1.37219829358634;
   fWeightMatrix0to1[6][11] = 1.62222484378975;
   fWeightMatrix0to1[7][11] = 0.895348764871019;
   fWeightMatrix0to1[8][11] = -3.28314822318247;
   fWeightMatrix0to1[9][11] = 3.12237257806804;
   fWeightMatrix0to1[10][11] = -1.75579388671227;
   fWeightMatrix0to1[11][11] = -1.30870849806538;
   fWeightMatrix0to1[12][11] = -0.310645784385028;
   fWeightMatrix0to1[13][11] = -1.47261132654811;
   fWeightMatrix0to1[14][11] = 0.512909595580034;
   fWeightMatrix0to1[15][11] = 1.25092633943935;
   fWeightMatrix0to1[16][11] = -1.43807128406806;
   fWeightMatrix0to1[17][11] = 0.591642837664658;
   fWeightMatrix0to1[18][11] = -0.2425133270317;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -0.781233682972753;
   fWeightMatrix1to2[0][1] = -0.166748604534083;
   fWeightMatrix1to2[0][2] = -0.287431809789274;
   fWeightMatrix1to2[0][3] = 0.436781718588502;
   fWeightMatrix1to2[0][4] = -0.154393614840588;
   fWeightMatrix1to2[0][5] = 0.125601215598984;
   fWeightMatrix1to2[0][6] = -0.222715246934134;
   fWeightMatrix1to2[0][7] = -0.797058159619929;
   fWeightMatrix1to2[0][8] = 0.930830531730282;
   fWeightMatrix1to2[0][9] = 1.30954812241524;
   fWeightMatrix1to2[0][10] = -0.268636248677027;
   fWeightMatrix1to2[0][11] = -0.216562328858736;
   fWeightMatrix1to2[0][12] = -0.573517289579407;
   fWeightMatrix1to2[0][13] = 0.0693356010406138;
   fWeightMatrix1to2[0][14] = -0.316787713886593;
   fWeightMatrix1to2[0][15] = -0.697036298043606;
   fWeightMatrix1to2[0][16] = -0.169763348813092;
   fWeightMatrix1to2[0][17] = 0.424145044098282;
   fWeightMatrix1to2[0][18] = 0.213524817256997;
   fWeightMatrix1to2[0][19] = -0.622368416259669;
}

inline double ReadMLPBNN::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = OutputActivationFnc(fWeights[2][o]);
   }

   return fWeights[2][0];
}

double ReadMLPBNN::ActivationFnc(double x) const {
   // sigmoid
   return 1.0/(1.0+exp(-x));
}
double ReadMLPBNN::OutputActivationFnc(double x) const {
   // sigmoid
   return 1.0/(1.0+exp(-x));
}
   
// Clean up
inline void ReadMLPBNN::Clear() 
{
   // nothing to clear
}
   inline double ReadMLPBNN::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            Transform( iV, -1 );
            retval = GetMvaValue__( iV );
         }
         else {
            std::vector<double> iV;
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(*varIt);
            }
            Transform( iV, -1 );
            retval = GetMvaValue__( iV );
         }
      }

      return retval;
   }

//_______________________________________________________________________
inline void ReadMLPBNN::InitTransform_1()
{
   // Normalization transformation, initialisation
   fMin_1[0][0] = -0.997974097729;
   fMax_1[0][0] = 0.997019350529;
   fMin_1[1][0] = -0.998661220074;
   fMax_1[1][0] = 0.996982336044;
   fMin_1[2][0] = -0.998661220074;
   fMax_1[2][0] = 0.997019350529;
   fMin_1[0][1] = -0.99699151516;
   fMax_1[0][1] = 0.994016289711;
   fMin_1[1][1] = -0.992805838585;
   fMax_1[1][1] = 0.992922723293;
   fMin_1[2][1] = -0.99699151516;
   fMax_1[2][1] = 0.994016289711;
   fMin_1[0][2] = -0.976840317249;
   fMax_1[0][2] = 0.993785560131;
   fMin_1[1][2] = -0.985854327679;
   fMax_1[1][2] = 0.987149775028;
   fMin_1[2][2] = -0.985854327679;
   fMax_1[2][2] = 0.993785560131;
   fMin_1[0][3] = -0.968796253204;
   fMax_1[0][3] = 0.966293692589;
   fMin_1[1][3] = -0.940587520599;
   fMax_1[1][3] = 0.983174741268;
   fMin_1[2][3] = -0.968796253204;
   fMax_1[2][3] = 0.983174741268;
   fMin_1[0][4] = -130.405899048;
   fMax_1[0][4] = 118.504402161;
   fMin_1[1][4] = -115.716400146;
   fMax_1[1][4] = 117.680900574;
   fMin_1[2][4] = -130.405899048;
   fMax_1[2][4] = 118.504402161;
   fMin_1[0][5] = -106.425300598;
   fMax_1[0][5] = 112.738800049;
   fMin_1[1][5] = -117.963996887;
   fMax_1[1][5] = 125.757499695;
   fMin_1[2][5] = -117.963996887;
   fMax_1[2][5] = 125.757499695;
   fMin_1[0][6] = -109.9036026;
   fMax_1[0][6] = 98.1610031128;
   fMin_1[1][6] = -88.397102356;
   fMax_1[1][6] = 94.7369003296;
   fMin_1[2][6] = -109.9036026;
   fMax_1[2][6] = 98.1610031128;
   fMin_1[0][7] = -95.6821975708;
   fMax_1[0][7] = 95.491897583;
   fMin_1[1][7] = -86.2520980835;
   fMax_1[1][7] = 86.9427032471;
   fMin_1[2][7] = -95.6821975708;
   fMax_1[2][7] = 95.491897583;
   fMin_1[0][8] = 25.3595142365;
   fMax_1[0][8] = 56077.5625;
   fMin_1[1][8] = 12.2331514359;
   fMax_1[1][8] = 79008.6171875;
   fMin_1[2][8] = 12.2331514359;
   fMax_1[2][8] = 79008.6171875;
   fMin_1[0][9] = 1;
   fMax_1[0][9] = 9;
   fMin_1[1][9] = 1;
   fMax_1[1][9] = 8;
   fMin_1[2][9] = 1;
   fMax_1[2][9] = 9;
   fMin_1[0][10] = 1;
   fMax_1[0][10] = 10;
   fMin_1[1][10] = 1;
   fMax_1[1][10] = 11;
   fMin_1[2][10] = 1;
   fMax_1[2][10] = 11;
}

//_______________________________________________________________________
inline void ReadMLPBNN::Transform_1( std::vector<double>& iv, int cls) const
{
   // Normalization transformation
   if (cls < 0 || cls > 2) {
   if (2 > 1 ) cls = 2;
      else cls = 2;
   }
   const int nVar = 11;

   // get indices of used variables

   // define the indices of the variables which are transformed by this transformation
   std::vector<int> indicesGet;
   std::vector<int> indicesPut;

   indicesGet.push_back( 0);
   indicesGet.push_back( 1);
   indicesGet.push_back( 2);
   indicesGet.push_back( 3);
   indicesGet.push_back( 4);
   indicesGet.push_back( 5);
   indicesGet.push_back( 6);
   indicesGet.push_back( 7);
   indicesGet.push_back( 8);
   indicesGet.push_back( 9);
   indicesGet.push_back( 10);
   indicesPut.push_back( 0);
   indicesPut.push_back( 1);
   indicesPut.push_back( 2);
   indicesPut.push_back( 3);
   indicesPut.push_back( 4);
   indicesPut.push_back( 5);
   indicesPut.push_back( 6);
   indicesPut.push_back( 7);
   indicesPut.push_back( 8);
   indicesPut.push_back( 9);
   indicesPut.push_back( 10);

   std::vector<double> dv(nVar);
   for (int ivar=0; ivar<nVar; ivar++) dv[ivar] = iv[indicesGet.at(ivar)];
   for (int ivar=0;ivar<11;ivar++) {
      double offset = fMin_1[cls][ivar];
      double scale  = 1.0/(fMax_1[cls][ivar]-fMin_1[cls][ivar]);
      iv[indicesPut.at(ivar)] = (dv[ivar]-offset)*scale * 2 - 1;
   }
}

//_______________________________________________________________________
inline void ReadMLPBNN::InitTransform_2()
{
   // Decorrelation transformation, initialisation
   fDecTF_2[0][0][0] = 1.60583867541;
   fDecTF_2[0][0][1] = 0.0233498739529;
   fDecTF_2[0][0][2] = 0.00542303580249;
   fDecTF_2[0][0][3] = -0.0018226035705;
   fDecTF_2[0][0][4] = -1.34991105313;
   fDecTF_2[0][0][5] = -0.00456043980069;
   fDecTF_2[0][0][6] = 0.00944479446555;
   fDecTF_2[0][0][7] = -0.00140884917666;
   fDecTF_2[0][0][8] = 0.00264253819191;
   fDecTF_2[0][0][9] = 0.00671644451476;
   fDecTF_2[0][0][10] = 0.0119618655301;
   fDecTF_2[0][1][0] = 0.0233498739529;
   fDecTF_2[0][1][1] = 2.47678030965;
   fDecTF_2[0][1][2] = 0.0402246757086;
   fDecTF_2[0][1][3] = 0.0112356587803;
   fDecTF_2[0][1][4] = 0.0133127114677;
   fDecTF_2[0][1][5] = -1.92274557393;
   fDecTF_2[0][1][6] = 0.0181777893198;
   fDecTF_2[0][1][7] = 0.0317493164951;
   fDecTF_2[0][1][8] = -0.0100186686034;
   fDecTF_2[0][1][9] = 0.00933717413305;
   fDecTF_2[0][1][10] = 0.0445262020717;
   fDecTF_2[0][2][0] = 0.00542303580249;
   fDecTF_2[0][2][1] = 0.0402246757086;
   fDecTF_2[0][2][2] = 4.05997091549;
   fDecTF_2[0][2][3] = 0.0464739754859;
   fDecTF_2[0][2][4] = 0.0152331494101;
   fDecTF_2[0][2][5] = 0.0219710033413;
   fDecTF_2[0][2][6] = -3.06173244007;
   fDecTF_2[0][2][7] = 0.0432559190684;
   fDecTF_2[0][2][8] = 0.00184033908056;
   fDecTF_2[0][2][9] = -0.0131979003575;
   fDecTF_2[0][2][10] = -0.00684472714591;
   fDecTF_2[0][3][0] = -0.0018226035705;
   fDecTF_2[0][3][1] = 0.0112356587803;
   fDecTF_2[0][3][2] = 0.0464739754859;
   fDecTF_2[0][3][3] = 6.68750586715;
   fDecTF_2[0][3][4] = 0.0130981369543;
   fDecTF_2[0][3][5] = 0.0423839066786;
   fDecTF_2[0][3][6] = -0.0189954694354;
   fDecTF_2[0][3][7] = -4.76796029469;
   fDecTF_2[0][3][8] = 0.0163808672025;
   fDecTF_2[0][3][9] = 0.00157258665233;
   fDecTF_2[0][3][10] = -0.0423162555547;
   fDecTF_2[0][4][0] = -1.34991105313;
   fDecTF_2[0][4][1] = 0.0133127114677;
   fDecTF_2[0][4][2] = 0.0152331494101;
   fDecTF_2[0][4][3] = 0.0130981369543;
   fDecTF_2[0][4][4] = 8.57377832594;
   fDecTF_2[0][4][5] = 0.0815965886948;
   fDecTF_2[0][4][6] = 0.0151258954793;
   fDecTF_2[0][4][7] = 0.0284884679502;
   fDecTF_2[0][4][8] = 0.0191949675761;
   fDecTF_2[0][4][9] = -0.0249194679696;
   fDecTF_2[0][4][10] = 0.0127827274662;
   fDecTF_2[0][5][0] = -0.00456043980069;
   fDecTF_2[0][5][1] = -1.92274557393;
   fDecTF_2[0][5][2] = 0.0219710033413;
   fDecTF_2[0][5][3] = 0.0423839066786;
   fDecTF_2[0][5][4] = 0.0815965886948;
   fDecTF_2[0][5][5] = 10.7150655641;
   fDecTF_2[0][5][6] = 0.0721508413047;
   fDecTF_2[0][5][7] = -0.0403668461461;
   fDecTF_2[0][5][8] = 0.0476901683971;
   fDecTF_2[0][5][9] = 0.0047293046541;
   fDecTF_2[0][5][10] = -0.0216757532587;
   fDecTF_2[0][6][0] = 0.00944479446555;
   fDecTF_2[0][6][1] = 0.0181777893198;
   fDecTF_2[0][6][2] = -3.06173244007;
   fDecTF_2[0][6][3] = -0.0189954694354;
   fDecTF_2[0][6][4] = 0.0151258954793;
   fDecTF_2[0][6][5] = 0.0721508413047;
   fDecTF_2[0][6][6] = 13.581718985;
   fDecTF_2[0][6][7] = 0.28105715112;
   fDecTF_2[0][6][8] = 0.00874481370051;
   fDecTF_2[0][6][9] = 0.00673210862734;
   fDecTF_2[0][6][10] = 0.0262125446299;
   fDecTF_2[0][7][0] = -0.00140884917666;
   fDecTF_2[0][7][1] = 0.0317493164951;
   fDecTF_2[0][7][2] = 0.0432559190684;
   fDecTF_2[0][7][3] = -4.76796029469;
   fDecTF_2[0][7][4] = 0.0284884679502;
   fDecTF_2[0][7][5] = -0.0403668461461;
   fDecTF_2[0][7][6] = 0.28105715112;
   fDecTF_2[0][7][7] = 19.076742408;
   fDecTF_2[0][7][8] = -0.0118177597058;
   fDecTF_2[0][7][9] = -0.0226310826154;
   fDecTF_2[0][7][10] = 0.0373760934212;
   fDecTF_2[0][8][0] = 0.00264253819191;
   fDecTF_2[0][8][1] = -0.0100186686034;
   fDecTF_2[0][8][2] = 0.00184033908056;
   fDecTF_2[0][8][3] = 0.0163808672025;
   fDecTF_2[0][8][4] = 0.0191949675761;
   fDecTF_2[0][8][5] = 0.0476901683971;
   fDecTF_2[0][8][6] = 0.00874481370051;
   fDecTF_2[0][8][7] = -0.0118177597058;
   fDecTF_2[0][8][8] = 9.12155642046;
   fDecTF_2[0][8][9] = -0.0512588283576;
   fDecTF_2[0][8][10] = 0.0720865615815;
   fDecTF_2[0][9][0] = 0.00671644451476;
   fDecTF_2[0][9][1] = 0.00933717413305;
   fDecTF_2[0][9][2] = -0.0131979003575;
   fDecTF_2[0][9][3] = 0.00157258665233;
   fDecTF_2[0][9][4] = -0.0249194679696;
   fDecTF_2[0][9][5] = 0.0047293046541;
   fDecTF_2[0][9][6] = 0.00673210862734;
   fDecTF_2[0][9][7] = -0.0226310826154;
   fDecTF_2[0][9][8] = -0.0512588283576;
   fDecTF_2[0][9][9] = 4.31831366483;
   fDecTF_2[0][9][10] = 0.377716205666;
   fDecTF_2[0][10][0] = 0.0119618655301;
   fDecTF_2[0][10][1] = 0.0445262020717;
   fDecTF_2[0][10][2] = -0.00684472714591;
   fDecTF_2[0][10][3] = -0.0423162555547;
   fDecTF_2[0][10][4] = 0.0127827274662;
   fDecTF_2[0][10][5] = -0.0216757532587;
   fDecTF_2[0][10][6] = 0.0262125446299;
   fDecTF_2[0][10][7] = 0.0373760934212;
   fDecTF_2[0][10][8] = 0.0720865615815;
   fDecTF_2[0][10][9] = 0.377716205666;
   fDecTF_2[0][10][10] = 4.13449638471;
   fDecTF_2[1][0][0] = 1.61314473999;
   fDecTF_2[1][0][1] = 0.0252707524879;
   fDecTF_2[1][0][2] = 0.00753766329598;
   fDecTF_2[1][0][3] = -0.00113351470216;
   fDecTF_2[1][0][4] = -1.35766863352;
   fDecTF_2[1][0][5] = -0.00727212254226;
   fDecTF_2[1][0][6] = -0.00582765796878;
   fDecTF_2[1][0][7] = -0.00649230455972;
   fDecTF_2[1][0][8] = -0.00250772413807;
   fDecTF_2[1][0][9] = -0.00708718931334;
   fDecTF_2[1][0][10] = -0.0304988400939;
   fDecTF_2[1][1][0] = 0.0252707524879;
   fDecTF_2[1][1][1] = 2.48959165629;
   fDecTF_2[1][1][2] = 0.00722896568599;
   fDecTF_2[1][1][3] = -0.0145817031179;
   fDecTF_2[1][1][4] = 0.00441116187765;
   fDecTF_2[1][1][5] = -1.96226500023;
   fDecTF_2[1][1][6] = 0.0274075832257;
   fDecTF_2[1][1][7] = 0.00735743430606;
   fDecTF_2[1][1][8] = -0.0132724990195;
   fDecTF_2[1][1][9] = 0.00509443814417;
   fDecTF_2[1][1][10] = -0.0407621445198;
   fDecTF_2[1][2][0] = 0.00753766329598;
   fDecTF_2[1][2][1] = 0.00722896568599;
   fDecTF_2[1][2][2] = 4.00429096493;
   fDecTF_2[1][2][3] = 0.0210718110677;
   fDecTF_2[1][2][4] = 0.00771396089054;
   fDecTF_2[1][2][5] = 0.0184515168749;
   fDecTF_2[1][2][6] = -2.92543007564;
   fDecTF_2[1][2][7] = -0.0111641574521;
   fDecTF_2[1][2][8] = -0.000276092255336;
   fDecTF_2[1][2][9] = -0.00123986791213;
   fDecTF_2[1][2][10] = -0.0725034491594;
   fDecTF_2[1][3][0] = -0.00113351470216;
   fDecTF_2[1][3][1] = -0.0145817031179;
   fDecTF_2[1][3][2] = 0.0210718110677;
   fDecTF_2[1][3][3] = 6.73799722045;
   fDecTF_2[1][3][4] = 0.00987740883915;
   fDecTF_2[1][3][5] = 0.0375076286465;
   fDecTF_2[1][3][6] = 0.0634727245033;
   fDecTF_2[1][3][7] = -4.8665932818;
   fDecTF_2[1][3][8] = 0.0063402038909;
   fDecTF_2[1][3][9] = -0.00815148006885;
   fDecTF_2[1][3][10] = -0.114677002755;
   fDecTF_2[1][4][0] = -1.35766863352;
   fDecTF_2[1][4][1] = 0.00441116187765;
   fDecTF_2[1][4][2] = 0.00771396089054;
   fDecTF_2[1][4][3] = 0.00987740883915;
   fDecTF_2[1][4][4] = 8.5992379205;
   fDecTF_2[1][4][5] = 0.0852648937493;
   fDecTF_2[1][4][6] = 0.0865782889146;
   fDecTF_2[1][4][7] = 0.0661216669846;
   fDecTF_2[1][4][8] = -0.0336378224467;
   fDecTF_2[1][4][9] = 0.0627318381041;
   fDecTF_2[1][4][10] = 0.0188673185785;
   fDecTF_2[1][5][0] = -0.00727212254226;
   fDecTF_2[1][5][1] = -1.96226500023;
   fDecTF_2[1][5][2] = 0.0184515168749;
   fDecTF_2[1][5][3] = 0.0375076286465;
   fDecTF_2[1][5][4] = 0.0852648937493;
   fDecTF_2[1][5][5] = 10.8847349978;
   fDecTF_2[1][5][6] = 0.040241089868;
   fDecTF_2[1][5][7] = 0.0623323764865;
   fDecTF_2[1][5][8] = 0.0322607253109;
   fDecTF_2[1][5][9] = 0.0231021818977;
   fDecTF_2[1][5][10] = -0.0206027089687;
   fDecTF_2[1][6][0] = -0.00582765796878;
   fDecTF_2[1][6][1] = 0.0274075832257;
   fDecTF_2[1][6][2] = -2.92543007564;
   fDecTF_2[1][6][3] = 0.0634727245033;
   fDecTF_2[1][6][4] = 0.0865782889146;
   fDecTF_2[1][6][5] = 0.040241089868;
   fDecTF_2[1][6][6] = 13.239143112;
   fDecTF_2[1][6][7] = 0.0577980287247;
   fDecTF_2[1][6][8] = -0.00589617362064;
   fDecTF_2[1][6][9] = 0.0290359057943;
   fDecTF_2[1][6][10] = -0.0477082036248;
   fDecTF_2[1][7][0] = -0.00649230455972;
   fDecTF_2[1][7][1] = 0.00735743430606;
   fDecTF_2[1][7][2] = -0.0111641574521;
   fDecTF_2[1][7][3] = -4.8665932818;
   fDecTF_2[1][7][4] = 0.0661216669846;
   fDecTF_2[1][7][5] = 0.0623323764865;
   fDecTF_2[1][7][6] = 0.0577980287247;
   fDecTF_2[1][7][7] = 19.0850404261;
   fDecTF_2[1][7][8] = -0.0260611101199;
   fDecTF_2[1][7][9] = 0.0205692245338;
   fDecTF_2[1][7][10] = -0.0543785235632;
   fDecTF_2[1][8][0] = -0.00250772413807;
   fDecTF_2[1][8][1] = -0.0132724990195;
   fDecTF_2[1][8][2] = -0.000276092255336;
   fDecTF_2[1][8][3] = 0.0063402038909;
   fDecTF_2[1][8][4] = -0.0336378224467;
   fDecTF_2[1][8][5] = 0.0322607253109;
   fDecTF_2[1][8][6] = -0.00589617362064;
   fDecTF_2[1][8][7] = -0.0260611101199;
   fDecTF_2[1][8][8] = 8.92759128458;
   fDecTF_2[1][8][9] = -0.0508031461922;
   fDecTF_2[1][8][10] = 0.0644364108882;
   fDecTF_2[1][9][0] = -0.00708718931334;
   fDecTF_2[1][9][1] = 0.00509443814417;
   fDecTF_2[1][9][2] = -0.00123986791213;
   fDecTF_2[1][9][3] = -0.00815148006885;
   fDecTF_2[1][9][4] = 0.0627318381041;
   fDecTF_2[1][9][5] = 0.0231021818977;
   fDecTF_2[1][9][6] = 0.0290359057943;
   fDecTF_2[1][9][7] = 0.0205692245338;
   fDecTF_2[1][9][8] = -0.0508031461922;
   fDecTF_2[1][9][9] = 4.32249837563;
   fDecTF_2[1][9][10] = 0.369858896415;
   fDecTF_2[1][10][0] = -0.0304988400939;
   fDecTF_2[1][10][1] = -0.0407621445198;
   fDecTF_2[1][10][2] = -0.0725034491594;
   fDecTF_2[1][10][3] = -0.114677002755;
   fDecTF_2[1][10][4] = 0.0188673185785;
   fDecTF_2[1][10][5] = -0.0206027089687;
   fDecTF_2[1][10][6] = -0.0477082036248;
   fDecTF_2[1][10][7] = -0.0543785235632;
   fDecTF_2[1][10][8] = 0.0644364108882;
   fDecTF_2[1][10][9] = 0.369858896415;
   fDecTF_2[1][10][10] = 4.13416792252;
   fDecTF_2[2][0][0] = 1.60237586938;
   fDecTF_2[2][0][1] = 0.0206445806735;
   fDecTF_2[2][0][2] = 0.00500056888391;
   fDecTF_2[2][0][3] = -0.00283092626396;
   fDecTF_2[2][0][4] = -1.3574356411;
   fDecTF_2[2][0][5] = -0.0065237675909;
   fDecTF_2[2][0][6] = -0.000160148797299;
   fDecTF_2[2][0][7] = -0.00521114211614;
   fDecTF_2[2][0][8] = -0.000628756399945;
   fDecTF_2[2][0][9] = -0.000128337302385;
   fDecTF_2[2][0][10] = -0.00905403742398;
   fDecTF_2[2][1][0] = 0.0206445806735;
   fDecTF_2[2][1][1] = 2.48059873128;
   fDecTF_2[2][1][2] = 0.0223615088208;
   fDecTF_2[2][1][3] = -0.00287617957129;
   fDecTF_2[2][1][4] = 0.00666613833059;
   fDecTF_2[2][1][5] = -1.94254793507;
   fDecTF_2[2][1][6] = 0.0213638956497;
   fDecTF_2[2][1][7] = 0.0178252486361;
   fDecTF_2[2][1][8] = -0.012215909106;
   fDecTF_2[2][1][9] = 0.00729617436739;
   fDecTF_2[2][1][10] = 0.00155688626444;
   fDecTF_2[2][2][0] = 0.00500056888391;
   fDecTF_2[2][2][1] = 0.0223615088208;
   fDecTF_2[2][2][2] = 4.03043965589;
   fDecTF_2[2][2][3] = 0.032582507204;
   fDecTF_2[2][2][4] = 0.010300822487;
   fDecTF_2[2][2][5] = 0.020240321741;
   fDecTF_2[2][2][6] = -2.99281992639;
   fDecTF_2[2][2][7] = 0.0152819722224;
   fDecTF_2[2][2][8] = 0.00048726373614;
   fDecTF_2[2][2][9] = -0.00722291503735;
   fDecTF_2[2][2][10] = -0.0406206662043;
   fDecTF_2[2][3][0] = -0.00283092626396;
   fDecTF_2[2][3][1] = -0.00287617957129;
   fDecTF_2[2][3][2] = 0.032582507204;
   fDecTF_2[2][3][3] = 6.71119926121;
   fDecTF_2[2][3][4] = 0.0103976451714;
   fDecTF_2[2][3][5] = 0.0400538708445;
   fDecTF_2[2][3][6] = 0.0217280292977;
   fDecTF_2[2][3][7] = -4.81668231293;
   fDecTF_2[2][3][8] = 0.0110270041116;
   fDecTF_2[2][3][9] = -0.00331256102242;
   fDecTF_2[2][3][10] = -0.0788654592855;
   fDecTF_2[2][4][0] = -1.3574356411;
   fDecTF_2[2][4][1] = 0.00666613833059;
   fDecTF_2[2][4][2] = 0.010300822487;
   fDecTF_2[2][4][3] = 0.0103976451714;
   fDecTF_2[2][4][4] = 8.58169549115;
   fDecTF_2[2][4][5] = 0.0827400750676;
   fDecTF_2[2][4][6] = 0.0492602864539;
   fDecTF_2[2][4][7] = 0.0463493588457;
   fDecTF_2[2][4][8] = -0.00839064572444;
   fDecTF_2[2][4][9] = 0.01881503483;
   fDecTF_2[2][4][10] = 0.0161004509867;
   fDecTF_2[2][5][0] = -0.0065237675909;
   fDecTF_2[2][5][1] = -1.94254793507;
   fDecTF_2[2][5][2] = 0.020240321741;
   fDecTF_2[2][5][3] = 0.0400538708445;
   fDecTF_2[2][5][4] = 0.0827400750676;
   fDecTF_2[2][5][5] = 10.7985964148;
   fDecTF_2[2][5][6] = 0.0562814763818;
   fDecTF_2[2][5][7] = 0.0100870611603;
   fDecTF_2[2][5][8] = 0.039847148633;
   fDecTF_2[2][5][9] = 0.0138030504509;
   fDecTF_2[2][5][10] = -0.021170009461;
   fDecTF_2[2][6][0] = -0.000160148797299;
   fDecTF_2[2][6][1] = 0.0213638956497;
   fDecTF_2[2][6][2] = -2.99281992639;
   fDecTF_2[2][6][3] = 0.0217280292977;
   fDecTF_2[2][6][4] = 0.0492602864539;
   fDecTF_2[2][6][5] = 0.0562814763818;
   fDecTF_2[2][6][6] = 13.4030552269;
   fDecTF_2[2][6][7] = 0.166612940656;
   fDecTF_2[2][6][8] = 0.000853504206196;
   fDecTF_2[2][6][9] = 0.0178150458534;
   fDecTF_2[2][6][10] = -0.0107637316606;
   fDecTF_2[2][7][0] = -0.00521114211614;
   fDecTF_2[2][7][1] = 0.0178252486361;
   fDecTF_2[2][7][2] = 0.0152819722224;
   fDecTF_2[2][7][3] = -4.81668231293;
   fDecTF_2[2][7][4] = 0.0463493588457;
   fDecTF_2[2][7][5] = 0.0100870611603;
   fDecTF_2[2][7][6] = 0.166612940656;
   fDecTF_2[2][7][7] = 19.0714764745;
   fDecTF_2[2][7][8] = -0.0195640820781;
   fDecTF_2[2][7][9] = -0.000945773083708;
   fDecTF_2[2][7][10] = -0.0109031777966;
   fDecTF_2[2][8][0] = -0.000628756399945;
   fDecTF_2[2][8][1] = -0.012215909106;
   fDecTF_2[2][8][2] = 0.00048726373614;
   fDecTF_2[2][8][3] = 0.0110270041116;
   fDecTF_2[2][8][4] = -0.00839064572444;
   fDecTF_2[2][8][5] = 0.039847148633;
   fDecTF_2[2][8][6] = 0.000853504206196;
   fDecTF_2[2][8][7] = -0.0195640820781;
   fDecTF_2[2][8][8] = 9.02233194301;
   fDecTF_2[2][8][9] = -0.050817838878;
   fDecTF_2[2][8][10] = 0.0675965912123;
   fDecTF_2[2][9][0] = -0.000128337302385;
   fDecTF_2[2][9][1] = 0.00729617436739;
   fDecTF_2[2][9][2] = -0.00722291503735;
   fDecTF_2[2][9][3] = -0.00331256102242;
   fDecTF_2[2][9][4] = 0.01881503483;
   fDecTF_2[2][9][5] = 0.0138030504509;
   fDecTF_2[2][9][6] = 0.0178150458534;
   fDecTF_2[2][9][7] = -0.000945773083708;
   fDecTF_2[2][9][8] = -0.050817838878;
   fDecTF_2[2][9][9] = 4.32004273186;
   fDecTF_2[2][9][10] = 0.373948430609;
   fDecTF_2[2][10][0] = -0.00905403742398;
   fDecTF_2[2][10][1] = 0.00155688626444;
   fDecTF_2[2][10][2] = -0.0406206662043;
   fDecTF_2[2][10][3] = -0.0788654592855;
   fDecTF_2[2][10][4] = 0.0161004509867;
   fDecTF_2[2][10][5] = -0.021170009461;
   fDecTF_2[2][10][6] = -0.0107637316606;
   fDecTF_2[2][10][7] = -0.0109031777966;
   fDecTF_2[2][10][8] = 0.0675965912123;
   fDecTF_2[2][10][9] = 0.373948430609;
   fDecTF_2[2][10][10] = 4.13034164939;
}

//_______________________________________________________________________
inline void ReadMLPBNN::Transform_2( std::vector<double>& iv, int cls) const
{
   // Decorrelation transformation
   if (cls < 0 || cls > 2) {
       if (2 > 1 ) cls = 2;
       else cls = 2;
   }

   // define the indices of the variables which are transformed by this transformation
   std::vector<int> indicesGet;
   std::vector<int> indicesPut;

   indicesGet.push_back( 0);
   indicesGet.push_back( 1);
   indicesGet.push_back( 2);
   indicesGet.push_back( 3);
   indicesGet.push_back( 4);
   indicesGet.push_back( 5);
   indicesGet.push_back( 6);
   indicesGet.push_back( 7);
   indicesGet.push_back( 8);
   indicesGet.push_back( 9);
   indicesGet.push_back( 10);
   indicesPut.push_back( 0);
   indicesPut.push_back( 1);
   indicesPut.push_back( 2);
   indicesPut.push_back( 3);
   indicesPut.push_back( 4);
   indicesPut.push_back( 5);
   indicesPut.push_back( 6);
   indicesPut.push_back( 7);
   indicesPut.push_back( 8);
   indicesPut.push_back( 9);
   indicesPut.push_back( 10);

   std::vector<double> tv;
   for (int i=0; i<11;i++) {
      double v = 0;
      for (int j=0; j<11; j++)
         v += iv[indicesGet.at(j)] * fDecTF_2[cls][i][j];
      tv.push_back(v);
   }
   for (int i=0; i<11;i++) iv[indicesPut.at(i)] = tv[i];
}

//_______________________________________________________________________
inline void ReadMLPBNN::InitTransform()
{
   InitTransform_1();
   InitTransform_2();
}

//_______________________________________________________________________
inline void ReadMLPBNN::Transform( std::vector<double>& iv, int sigOrBgd ) const
{
   Transform_1( iv, sigOrBgd );
   Transform_2( iv, sigOrBgd );
}

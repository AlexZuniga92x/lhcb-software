// Class: ReadMLPBNN
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLPBNN
TMVA Release   : 4.1.2         [262402]
ROOT Release   : 5.30/04       [335364]
Creator        : krocker
Date           : Mon Apr 29 01:44:15 2013
Host           : Linux lxbuild148.cern.ch 2.6.18-194.26.1.el5 #1 SMP Wed Nov 10 09:45:46 CET 2010 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /auto/sigma0/work2/krocker/tagging2011/SSK-tagging/phd/MCStudies/TMVABatch/final/confNN1NodesFullchi2/11
Training events: 148134
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
NCycles: "1000" [Number of training cycles]
HiddenLayers: "N+11" [Specification of hidden layer architecture]
NeuronType: "sigmoid" [Neuron activation function type]
EstimatorType: "CE" [MSE (Mean Square Estimator) for Gaussian Likelihood or CE(Cross-Entropy) for Bernoulli Likelihood]
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
VarTransform: "N,D" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
H: "False" [Print method-specific help message]
TrainingMethod: "BFGS" [Train with Back-Propagation (BP), BFGS Algorithm (BFGS), or Genetic Algorithm (GA - slower and worse)]
TestRate: "5" [Test for overtraining performed at each #th epochs]
UseRegulator: "True" [Use regulator to avoid over-training]
CalculateErrors: "True" [Calculates inverse Hessian matrix at the end of the training to be able to calculate the uncertainties of an MVA value]
# Default:
RandomSeed: "1" [Random seed for initial synapse weights (0 means unique seed for each run; default value '1')]
NeuronInputType: "sum" [Neuron input function type]
VerbosityLevel: "Default" [Verbosity level]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
LearningRate: "2.000000e-02" [ANN learning rate parameter]
DecayRate: "1.000000e-02" [Decay rate for learning parameter]
EpochMonitoring: "False" [Provide epoch-wise monitoring plots according to TestRate (caution: causes big ROOT output file!)]
Sampling: "1.000000e+00" [Only 'Sampling' (randomly selected) events are trained each epoch]
SamplingEpoch: "1.000000e+00" [Sampling is used for the first 'SamplingEpoch' epochs, afterwards, all events are taken for training]
SamplingImportance: "1.000000e+00" [ The sampling weights of events in epochs which successful (worse estimator than before) are multiplied with SamplingImportance, else they are divided.]
SamplingTraining: "True" [The training sample is sampled]
SamplingTesting: "False" [The testing sample is sampled]
ResetStep: "50" [How often BFGS should reset history]
Tau: "3.000000e+00" [LineSearch "size step"]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
ConvergenceImprove: "1.000000e-30" [Minimum improvement which counts as improvement (<0 means automatic convergence check is turned off)]
ConvergenceTests: "-1" [Number of steps (without improvement) required for convergence (<0 means automatic convergence check is turned off)]
UpdateLimit: "10000" [Maximum times of regulator update]
WeightRange: "1.000000e+00" [Take the events for the estimator calculations from small deviations from the desired value to large deviations only over the weight range]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 11
log(ntrack)                   log_ntrack_                   log(ntrack)                   number of tagging tracks                                        'D'    [0,4.12713432312]
npv                           npv                           npv                           number of PVs                                                   'I'    [1,8]
log(ptB)                      log_ptB_                      log(ptB)                      transverse momentum B         GeV/c                             'D'    [4.89971923828,11.3495807648]
log(ptT)                      log_ptT_                      log(ptT)                      transverse momentum Track     GeV/c                             'D'    [3.92620253563,9.20820903778]
log(ptrel)                    log_ptrel_                    log(ptrel)                    relative pt                   GeV/c                             'D'    [0.708819389343,10.2732667923]
log(pT)                       log_pT_                       log(pT)                       momentum track                GeV/c                             'D'    [7.60090589523,12.194144249]
log(dEta)                     log_dEta_                     log(dEta)                     delta Eta                                                       'D'    [-11.0718822479,1.57367753983]
log(dphi)                     log_dphi_                     log(dphi)                     delta Phi                                                       'D'    [-10.1332616806,0.405453294516]
log(ip)                       log_ip_                       log(ip)                       ip                                                              'D'    [-9.0179233551,8.12757205963]
log(ipSig)                    log_ipSig_                    log(ipSig)                    ip sig                                                          'D'    [-5.68606090546,10.3189296722]
log(lcs)                      log_lcs_                      log(lcs)                      lcs                                                             'D'    [-1.59483349323,2.30241823196]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadMLPBNN : public IClassifierReader {

 public:

   // constructor
   ReadMLPBNN( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLPBNN" ),
        fNvars( 11 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "log(ntrack)", "npv", "log(ptB)", "log(ptT)", "log(ptrel)", "log(pT)", "log(dEta)", "log(dphi)", "log(ip)", "log(ipSig)", "log(lcs)" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = -3.65711641311646;
      fVmax[0] = 3.33813810348511;
      fVmin[1] = -4.48980665206909;
      fVmax[1] = 3.94449281692505;
      fVmin[2] = -6.09631586074829;
      fVmax[2] = 6.70387363433838;
      fVmin[3] = -3.40964317321777;
      fVmax[3] = 4.86779594421387;
      fVmin[4] = -7.86115264892578;
      fVmax[4] = 3.78709626197815;
      fVmin[5] = -3.485347032547;
      fVmax[5] = 3.31528449058533;
      fVmin[6] = -6.68749189376831;
      fVmax[6] = 5.91641807556152;
      fVmin[7] = -5.88268995285034;
      fVmax[7] = 6.14725589752197;
      fVmin[8] = -4.98753643035889;
      fVmax[8] = 6.05790567398071;
      fVmin[9] = -5.65902614593506;
      fVmax[9] = 7.08962059020996;
      fVmin[10] = -2.85790824890137;
      fVmax[10] = 3.65574836730957;

      // initialize input variable types
      fType[0] = 'D';
      fType[1] = 'I';
      fType[2] = 'D';
      fType[3] = 'D';
      fType[4] = 'D';
      fType[5] = 'D';
      fType[6] = 'D';
      fType[7] = 'D';
      fType[8] = 'D';
      fType[9] = 'D';
      fType[10] = 'D';

      // initialize constants
      Initialize();

      // initialize transformation
      InitTransform();
   }

   // destructor
   virtual ~ReadMLPBNN() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // input variable transformation

   double fMin_1[3][11];
   double fMax_1[3][11];

   double fDecTF_2[3][11][11];
   void InitTransform_1();
   void Transform_1( std::vector<double> & iv, int sigOrBgd ) const;
   void InitTransform_2();
   void Transform_2( std::vector<double> & iv, int sigOrBgd ) const;
   void InitTransform();
   void Transform( std::vector<double> & iv, int sigOrBgd ) const;

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[11];
   double fVmax[11];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[11];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;
   double OutputActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[3];
   double fWeightMatrix0to1[23][12];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[1][23];   // weight matrix from layer 1 to 2

   double * fWeights[3];
};

inline void ReadMLPBNN::Initialize()
{
   // build network structure
   fLayers = 3;
   fLayerSize[0] = 12; fWeights[0] = new double[12]; 
   fLayerSize[1] = 23; fWeights[1] = new double[23]; 
   fLayerSize[2] = 1; fWeights[2] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.174733200917237;
   fWeightMatrix0to1[1][0] = 0.394694013430532;
   fWeightMatrix0to1[2][0] = -0.0609960760997706;
   fWeightMatrix0to1[3][0] = -0.05765443609178;
   fWeightMatrix0to1[4][0] = 0.0392299733367137;
   fWeightMatrix0to1[5][0] = -0.181634648836842;
   fWeightMatrix0to1[6][0] = -0.0526405845018272;
   fWeightMatrix0to1[7][0] = 0.234165363887705;
   fWeightMatrix0to1[8][0] = 0.047227236119799;
   fWeightMatrix0to1[9][0] = -0.11576541629332;
   fWeightMatrix0to1[10][0] = 0.0785680965356499;
   fWeightMatrix0to1[11][0] = 0.167778479169557;
   fWeightMatrix0to1[12][0] = -0.110453739481734;
   fWeightMatrix0to1[13][0] = -0.0289053808703339;
   fWeightMatrix0to1[14][0] = -0.114863735840694;
   fWeightMatrix0to1[15][0] = -0.0761376223685074;
   fWeightMatrix0to1[16][0] = 0.160400533904836;
   fWeightMatrix0to1[17][0] = 0.0335462559227745;
   fWeightMatrix0to1[18][0] = -0.0299129476060797;
   fWeightMatrix0to1[19][0] = 0.0593172958591635;
   fWeightMatrix0to1[20][0] = 0.00699594924276646;
   fWeightMatrix0to1[21][0] = -0.0618394033784457;
   fWeightMatrix0to1[0][1] = 0.0837312290937859;
   fWeightMatrix0to1[1][1] = -0.0136024106807348;
   fWeightMatrix0to1[2][1] = -0.533095979011927;
   fWeightMatrix0to1[3][1] = -0.380778903796004;
   fWeightMatrix0to1[4][1] = 0.265286091195008;
   fWeightMatrix0to1[5][1] = -0.245515448719028;
   fWeightMatrix0to1[6][1] = -1.33156163143002;
   fWeightMatrix0to1[7][1] = -0.500752644338731;
   fWeightMatrix0to1[8][1] = -0.0735795427080574;
   fWeightMatrix0to1[9][1] = -0.0677781015185353;
   fWeightMatrix0to1[10][1] = -0.0662563975076744;
   fWeightMatrix0to1[11][1] = 0.182905661621781;
   fWeightMatrix0to1[12][1] = 0.0729742895210988;
   fWeightMatrix0to1[13][1] = -0.198734685288694;
   fWeightMatrix0to1[14][1] = -0.521413349507669;
   fWeightMatrix0to1[15][1] = 0.334704287344616;
   fWeightMatrix0to1[16][1] = 0.199231695525962;
   fWeightMatrix0to1[17][1] = 0.00362735960456776;
   fWeightMatrix0to1[18][1] = 0.442923621962046;
   fWeightMatrix0to1[19][1] = -0.0509129813212124;
   fWeightMatrix0to1[20][1] = 0.30033186014945;
   fWeightMatrix0to1[21][1] = 0.0815308135178201;
   fWeightMatrix0to1[0][2] = -0.182065770291973;
   fWeightMatrix0to1[1][2] = -0.00862205300223028;
   fWeightMatrix0to1[2][2] = 0.207253477007086;
   fWeightMatrix0to1[3][2] = 0.217038462269418;
   fWeightMatrix0to1[4][2] = 0.338148922144383;
   fWeightMatrix0to1[5][2] = 0.00683267617750278;
   fWeightMatrix0to1[6][2] = 0.0087897817797786;
   fWeightMatrix0to1[7][2] = 0.0415834746475395;
   fWeightMatrix0to1[8][2] = 0.0170535368896546;
   fWeightMatrix0to1[9][2] = 0.050865693586434;
   fWeightMatrix0to1[10][2] = -0.345312800575834;
   fWeightMatrix0to1[11][2] = -0.0707901834789433;
   fWeightMatrix0to1[12][2] = 0.147980915307293;
   fWeightMatrix0to1[13][2] = -0.317451266310871;
   fWeightMatrix0to1[14][2] = -0.2232612610563;
   fWeightMatrix0to1[15][2] = -0.0837440162580976;
   fWeightMatrix0to1[16][2] = -0.0709436771894241;
   fWeightMatrix0to1[17][2] = 0.235746130903102;
   fWeightMatrix0to1[18][2] = -0.251758994935866;
   fWeightMatrix0to1[19][2] = -0.0169759539759923;
   fWeightMatrix0to1[20][2] = 0.505105286167568;
   fWeightMatrix0to1[21][2] = -0.224756520844008;
   fWeightMatrix0to1[0][3] = 0.968938660068656;
   fWeightMatrix0to1[1][3] = -0.282458010416579;
   fWeightMatrix0to1[2][3] = 0.648239720783425;
   fWeightMatrix0to1[3][3] = -0.696335722643755;
   fWeightMatrix0to1[4][3] = -0.421609761539764;
   fWeightMatrix0to1[5][3] = -1.43809819613326;
   fWeightMatrix0to1[6][3] = 0.144434972486285;
   fWeightMatrix0to1[7][3] = 1.00210987011666;
   fWeightMatrix0to1[8][3] = 0.402478717247553;
   fWeightMatrix0to1[9][3] = 0.319462881037351;
   fWeightMatrix0to1[10][3] = -0.507608286679516;
   fWeightMatrix0to1[11][3] = 0.393652523103686;
   fWeightMatrix0to1[12][3] = 1.25705171918712;
   fWeightMatrix0to1[13][3] = -0.423209904346189;
   fWeightMatrix0to1[14][3] = -0.872209774389661;
   fWeightMatrix0to1[15][3] = 0.35406681527282;
   fWeightMatrix0to1[16][3] = 0.357602549609033;
   fWeightMatrix0to1[17][3] = 0.888485315279824;
   fWeightMatrix0to1[18][3] = 0.278171994546729;
   fWeightMatrix0to1[19][3] = 0.328044078217834;
   fWeightMatrix0to1[20][3] = 0.401921973813098;
   fWeightMatrix0to1[21][3] = 0.607195781886794;
   fWeightMatrix0to1[0][4] = -0.413279637894317;
   fWeightMatrix0to1[1][4] = -0.288750144863238;
   fWeightMatrix0to1[2][4] = 0.276511248059324;
   fWeightMatrix0to1[3][4] = -0.236087161691948;
   fWeightMatrix0to1[4][4] = 0.182042541649667;
   fWeightMatrix0to1[5][4] = -0.515519096739725;
   fWeightMatrix0to1[6][4] = 0.653116052411836;
   fWeightMatrix0to1[7][4] = 0.11031083357994;
   fWeightMatrix0to1[8][4] = 0.130558656622422;
   fWeightMatrix0to1[9][4] = -0.98551218109381;
   fWeightMatrix0to1[10][4] = -0.249393106435892;
   fWeightMatrix0to1[11][4] = 0.070898829362441;
   fWeightMatrix0to1[12][4] = -0.464425417399773;
   fWeightMatrix0to1[13][4] = -0.657270925932471;
   fWeightMatrix0to1[14][4] = 0.266623478748088;
   fWeightMatrix0to1[15][4] = 0.223573443421596;
   fWeightMatrix0to1[16][4] = 0.0145535804585051;
   fWeightMatrix0to1[17][4] = 1.11154096691884;
   fWeightMatrix0to1[18][4] = -0.226403967652684;
   fWeightMatrix0to1[19][4] = 0.185630779889405;
   fWeightMatrix0to1[20][4] = -0.199963181945055;
   fWeightMatrix0to1[21][4] = -0.296806814608295;
   fWeightMatrix0to1[0][5] = -1.38733987114538;
   fWeightMatrix0to1[1][5] = 0.205475469768229;
   fWeightMatrix0to1[2][5] = -0.262496656535256;
   fWeightMatrix0to1[3][5] = -0.571178209435806;
   fWeightMatrix0to1[4][5] = -0.597937422066992;
   fWeightMatrix0to1[5][5] = 0.31065036625801;
   fWeightMatrix0to1[6][5] = 0.00370458317524628;
   fWeightMatrix0to1[7][5] = -0.642150176235261;
   fWeightMatrix0to1[8][5] = 0.199142214882531;
   fWeightMatrix0to1[9][5] = -0.481381748969014;
   fWeightMatrix0to1[10][5] = -1.03304394023732;
   fWeightMatrix0to1[11][5] = -0.136375793488978;
   fWeightMatrix0to1[12][5] = -0.258651088439494;
   fWeightMatrix0to1[13][5] = -0.299435288135075;
   fWeightMatrix0to1[14][5] = -0.506478669705185;
   fWeightMatrix0to1[15][5] = -0.191027527783103;
   fWeightMatrix0to1[16][5] = 0.272292991180802;
   fWeightMatrix0to1[17][5] = 0.544889442485131;
   fWeightMatrix0to1[18][5] = 0.463564022652381;
   fWeightMatrix0to1[19][5] = 1.18961798739961;
   fWeightMatrix0to1[20][5] = -0.204984758286762;
   fWeightMatrix0to1[21][5] = -0.154795099741666;
   fWeightMatrix0to1[0][6] = -0.169948605637567;
   fWeightMatrix0to1[1][6] = -0.255875110315292;
   fWeightMatrix0to1[2][6] = 0.525913341457038;
   fWeightMatrix0to1[3][6] = 0.450747008670119;
   fWeightMatrix0to1[4][6] = 0.542764056895473;
   fWeightMatrix0to1[5][6] = -0.460783508410919;
   fWeightMatrix0to1[6][6] = 0.13159378885086;
   fWeightMatrix0to1[7][6] = 0.0561814206341062;
   fWeightMatrix0to1[8][6] = 0.0239323562610069;
   fWeightMatrix0to1[9][6] = -0.62575218670015;
   fWeightMatrix0to1[10][6] = 0.0496213333278059;
   fWeightMatrix0to1[11][6] = 0.0856954132121786;
   fWeightMatrix0to1[12][6] = -0.530129511851888;
   fWeightMatrix0to1[13][6] = 0.448994549875697;
   fWeightMatrix0to1[14][6] = 0.104713365912502;
   fWeightMatrix0to1[15][6] = -0.434114548279832;
   fWeightMatrix0to1[16][6] = 0.018913429058494;
   fWeightMatrix0to1[17][6] = 0.424410637930032;
   fWeightMatrix0to1[18][6] = -0.401108257255978;
   fWeightMatrix0to1[19][6] = 0.251420284685645;
   fWeightMatrix0to1[20][6] = 0.809165708564495;
   fWeightMatrix0to1[21][6] = -0.571758889770247;
   fWeightMatrix0to1[0][7] = 0.176370685924532;
   fWeightMatrix0to1[1][7] = -0.127514082683569;
   fWeightMatrix0to1[2][7] = 0.396960078264162;
   fWeightMatrix0to1[3][7] = 0.527012050280813;
   fWeightMatrix0to1[4][7] = 0.753409396642784;
   fWeightMatrix0to1[5][7] = -0.33004862718834;
   fWeightMatrix0to1[6][7] = -0.181645252615652;
   fWeightMatrix0to1[7][7] = -0.0181024027071836;
   fWeightMatrix0to1[8][7] = 0.00197272960108568;
   fWeightMatrix0to1[9][7] = -0.334352671401146;
   fWeightMatrix0to1[10][7] = 0.233109957809706;
   fWeightMatrix0to1[11][7] = 0.0492887506434582;
   fWeightMatrix0to1[12][7] = -0.175706845154751;
   fWeightMatrix0to1[13][7] = 0.207616990388611;
   fWeightMatrix0to1[14][7] = 0.162269321447911;
   fWeightMatrix0to1[15][7] = -0.617837978787891;
   fWeightMatrix0to1[16][7] = 0.133337778212555;
   fWeightMatrix0to1[17][7] = 0.459562502839697;
   fWeightMatrix0to1[18][7] = -0.368772392043696;
   fWeightMatrix0to1[19][7] = 0.0235216606769222;
   fWeightMatrix0to1[20][7] = 0.822229925283797;
   fWeightMatrix0to1[21][7] = -2.95193959962909;
   fWeightMatrix0to1[0][8] = -0.0267987943789656;
   fWeightMatrix0to1[1][8] = 0.18377499528792;
   fWeightMatrix0to1[2][8] = 0.39185804130772;
   fWeightMatrix0to1[3][8] = -3.24375988518932;
   fWeightMatrix0to1[4][8] = -1.05388574536881;
   fWeightMatrix0to1[5][8] = 2.03186249123235;
   fWeightMatrix0to1[6][8] = 0.815293511752853;
   fWeightMatrix0to1[7][8] = -0.88335779503889;
   fWeightMatrix0to1[8][8] = -0.422221648834648;
   fWeightMatrix0to1[9][8] = 0.097427601549573;
   fWeightMatrix0to1[10][8] = 0.181304279138959;
   fWeightMatrix0to1[11][8] = 2.68764205586112;
   fWeightMatrix0to1[12][8] = -0.527576493726778;
   fWeightMatrix0to1[13][8] = 0.171725579656922;
   fWeightMatrix0to1[14][8] = 0.579569629239142;
   fWeightMatrix0to1[15][8] = 1.45273882190743;
   fWeightMatrix0to1[16][8] = 0.895321310109766;
   fWeightMatrix0to1[17][8] = 0.122724625397851;
   fWeightMatrix0to1[18][8] = -1.40135467615516;
   fWeightMatrix0to1[19][8] = -0.302371350605292;
   fWeightMatrix0to1[20][8] = -1.53719045635555;
   fWeightMatrix0to1[21][8] = 0.112343156234398;
   fWeightMatrix0to1[0][9] = 0.0408433094638526;
   fWeightMatrix0to1[1][9] = -0.220295827672517;
   fWeightMatrix0to1[2][9] = -0.327787853370695;
   fWeightMatrix0to1[3][9] = -3.5327563486212;
   fWeightMatrix0to1[4][9] = -0.0415296964302937;
   fWeightMatrix0to1[5][9] = 1.52775854994666;
   fWeightMatrix0to1[6][9] = 0.8348089323653;
   fWeightMatrix0to1[7][9] = -0.444734958548545;
   fWeightMatrix0to1[8][9] = -0.153536541365606;
   fWeightMatrix0to1[9][9] = -0.0918992895577264;
   fWeightMatrix0to1[10][9] = 0.31892181066321;
   fWeightMatrix0to1[11][9] = 3.18704387554204;
   fWeightMatrix0to1[12][9] = -0.00287446444139569;
   fWeightMatrix0to1[13][9] = -0.556017717548323;
   fWeightMatrix0to1[14][9] = -0.448165759138977;
   fWeightMatrix0to1[15][9] = -0.0921147224596013;
   fWeightMatrix0to1[16][9] = 1.00661699713541;
   fWeightMatrix0to1[17][9] = 0.0661568866067304;
   fWeightMatrix0to1[18][9] = 1.43649106787466;
   fWeightMatrix0to1[19][9] = -0.135870751434828;
   fWeightMatrix0to1[20][9] = 0.94276154877579;
   fWeightMatrix0to1[21][9] = -0.2521234119632;
   fWeightMatrix0to1[0][10] = 0.0785985304192781;
   fWeightMatrix0to1[1][10] = -0.0431201684309044;
   fWeightMatrix0to1[2][10] = -0.342189580040876;
   fWeightMatrix0to1[3][10] = -0.683825948438091;
   fWeightMatrix0to1[4][10] = 1.07229980515223;
   fWeightMatrix0to1[5][10] = 0.294074859880344;
   fWeightMatrix0to1[6][10] = 0.588535207201831;
   fWeightMatrix0to1[7][10] = -0.765720183639874;
   fWeightMatrix0to1[8][10] = -1.77173813873784;
   fWeightMatrix0to1[9][10] = -0.112283128133002;
   fWeightMatrix0to1[10][10] = -0.0170222780988793;
   fWeightMatrix0to1[11][10] = 1.05821149983175;
   fWeightMatrix0to1[12][10] = -0.194728312412701;
   fWeightMatrix0to1[13][10] = -1.00067626373436;
   fWeightMatrix0to1[14][10] = 0.14329762213387;
   fWeightMatrix0to1[15][10] = -1.21259420151494;
   fWeightMatrix0to1[16][10] = 1.00272549771169;
   fWeightMatrix0to1[17][10] = 0.136023612471818;
   fWeightMatrix0to1[18][10] = 0.0931271131037089;
   fWeightMatrix0to1[19][10] = -1.88918634294691;
   fWeightMatrix0to1[20][10] = -1.03604956291761;
   fWeightMatrix0to1[21][10] = -0.62247226802231;
   fWeightMatrix0to1[0][11] = -2.26790687436588;
   fWeightMatrix0to1[1][11] = 0.761289889383385;
   fWeightMatrix0to1[2][11] = -1.35040531338914;
   fWeightMatrix0to1[3][11] = 1.62853266702864;
   fWeightMatrix0to1[4][11] = -0.745460780323617;
   fWeightMatrix0to1[5][11] = -1.68761396702922;
   fWeightMatrix0to1[6][11] = 1.01275514744549;
   fWeightMatrix0to1[7][11] = -0.469649071144089;
   fWeightMatrix0to1[8][11] = 1.56752496666007;
   fWeightMatrix0to1[9][11] = 1.50326857838272;
   fWeightMatrix0to1[10][11] = 0.582091691161254;
   fWeightMatrix0to1[11][11] = 1.61630364471775;
   fWeightMatrix0to1[12][11] = -2.29361248679976;
   fWeightMatrix0to1[13][11] = -0.248536988149765;
   fWeightMatrix0to1[14][11] = -0.515907966478715;
   fWeightMatrix0to1[15][11] = -1.09601243431998;
   fWeightMatrix0to1[16][11] = 1.18913097310128;
   fWeightMatrix0to1[17][11] = -4.6914748217516;
   fWeightMatrix0to1[18][11] = -1.54647434098459;
   fWeightMatrix0to1[19][11] = 3.57058036332474;
   fWeightMatrix0to1[20][11] = 1.81683215467134;
   fWeightMatrix0to1[21][11] = -0.314310187710869;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = -2.26906045499542;
   fWeightMatrix1to2[0][1] = -4.6281043535932;
   fWeightMatrix1to2[0][2] = -1.38111609209447;
   fWeightMatrix1to2[0][3] = 2.57525829730539;
   fWeightMatrix1to2[0][4] = 0.0709212753796283;
   fWeightMatrix1to2[0][5] = 2.40061953498098;
   fWeightMatrix1to2[0][6] = -0.628197983092913;
   fWeightMatrix1to2[0][7] = 2.03543715887076;
   fWeightMatrix1to2[0][8] = 4.1348118781367;
   fWeightMatrix1to2[0][9] = 2.27413494440195;
   fWeightMatrix1to2[0][10] = -3.25968124150876;
   fWeightMatrix1to2[0][11] = -1.61745808881962;
   fWeightMatrix1to2[0][12] = 3.56248018006757;
   fWeightMatrix1to2[0][13] = 1.40222494479302;
   fWeightMatrix1to2[0][14] = 1.47156096130413;
   fWeightMatrix1to2[0][15] = -1.03279930256427;
   fWeightMatrix1to2[0][16] = 2.08001972490467;
   fWeightMatrix1to2[0][17] = -3.17891584146796;
   fWeightMatrix1to2[0][18] = -2.84524844857914;
   fWeightMatrix1to2[0][19] = -2.2199180153201;
   fWeightMatrix1to2[0][20] = -0.680697217106953;
   fWeightMatrix1to2[0][21] = -3.48138228156418;
   fWeightMatrix1to2[0][22] = -1.67457491458527;
}

inline double ReadMLPBNN::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = OutputActivationFnc(fWeights[2][o]);
   }

   return fWeights[2][0];
}

double ReadMLPBNN::ActivationFnc(double x) const {
   // sigmoid
   return 1.0/(1.0+exp(-x));
}
double ReadMLPBNN::OutputActivationFnc(double x) const {
   // sigmoid
   return 1.0/(1.0+exp(-x));
}
   
// Clean up
inline void ReadMLPBNN::Clear() 
{
   // nothing to clear
}
   inline double ReadMLPBNN::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            Transform( iV, -1 );
            retval = GetMvaValue__( iV );
         }
         else {
            std::vector<double> iV;
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(*varIt);
            }
            Transform( iV, -1 );
            retval = GetMvaValue__( iV );
         }
      }

      return retval;
   }

//_______________________________________________________________________
inline void ReadMLPBNN::InitTransform_1()
{
   // Normalization transformation, initialisation
   fMin_1[0][0] = 0;
   fMax_1[0][0] = 4.0604429245;
   fMin_1[1][0] = 0;
   fMax_1[1][0] = 4.12713432312;
   fMin_1[2][0] = 0;
   fMax_1[2][0] = 4.12713432312;
   fMin_1[0][1] = 1;
   fMax_1[0][1] = 8;
   fMin_1[1][1] = 1;
   fMax_1[1][1] = 8;
   fMin_1[2][1] = 1;
   fMax_1[2][1] = 8;
   fMin_1[0][2] = 4.89971923828;
   fMax_1[0][2] = 11.3495807648;
   fMin_1[1][2] = 5.44963359833;
   fMax_1[1][2] = 11.2234249115;
   fMin_1[2][2] = 4.89971923828;
   fMax_1[2][2] = 11.3495807648;
   fMin_1[0][3] = 4.09763765335;
   fMax_1[0][3] = 9.20820903778;
   fMin_1[1][3] = 3.92620253563;
   fMax_1[1][3] = 9.19036769867;
   fMin_1[2][3] = 3.92620253563;
   fMax_1[2][3] = 9.20820903778;
   fMin_1[0][4] = 0.708819389343;
   fMax_1[0][4] = 10.2732667923;
   fMin_1[1][4] = 1.09698462486;
   fMax_1[1][4] = 10.2399215698;
   fMin_1[2][4] = 0.708819389343;
   fMax_1[2][4] = 10.2732667923;
   fMin_1[0][5] = 7.60106563568;
   fMax_1[0][5] = 12.194144249;
   fMin_1[1][5] = 7.60090589523;
   fMax_1[1][5] = 12.1139087677;
   fMin_1[2][5] = 7.60090589523;
   fMax_1[2][5] = 12.194144249;
   fMin_1[0][6] = -11.0718822479;
   fMax_1[0][6] = 1.57367753983;
   fMin_1[1][6] = -10.966583252;
   fMax_1[1][6] = 1.46007454395;
   fMin_1[2][6] = -11.0718822479;
   fMax_1[2][6] = 1.57367753983;
   fMin_1[0][7] = -5.29573583603;
   fMax_1[0][7] = 0.405453294516;
   fMin_1[1][7] = -10.1332616806;
   fMax_1[1][7] = 0.405449032784;
   fMin_1[2][7] = -10.1332616806;
   fMax_1[2][7] = 0.405453294516;
   fMin_1[0][8] = -9.0179233551;
   fMax_1[0][8] = 6.39792871475;
   fMin_1[1][8] = -8.1180934906;
   fMax_1[1][8] = 8.12757205963;
   fMin_1[2][8] = -9.0179233551;
   fMax_1[2][8] = 8.12757205963;
   fMin_1[0][9] = -5.68606090546;
   fMax_1[0][9] = 9.38759803772;
   fMin_1[1][9] = -4.56600093842;
   fMax_1[1][9] = 10.3189296722;
   fMin_1[2][9] = -5.68606090546;
   fMax_1[2][9] = 10.3189296722;
   fMin_1[0][10] = -1.45351946354;
   fMax_1[0][10] = 2.30241823196;
   fMin_1[1][10] = -1.59483349323;
   fMax_1[1][10] = 2.30228304863;
   fMin_1[2][10] = -1.59483349323;
   fMax_1[2][10] = 2.30241823196;
}

//_______________________________________________________________________
inline void ReadMLPBNN::Transform_1( std::vector<double>& iv, int cls) const
{
   // Normalization transformation
   if (cls < 0 || cls > 2) {
   if (2 > 1 ) cls = 2;
      else cls = 2;
   }
   const int nVar = 11;

   // get indices of used variables

   // define the indices of the variables which are transformed by this transformation
   std::vector<int> indicesGet;
   std::vector<int> indicesPut;

   indicesGet.push_back( 0);
   indicesGet.push_back( 1);
   indicesGet.push_back( 2);
   indicesGet.push_back( 3);
   indicesGet.push_back( 4);
   indicesGet.push_back( 5);
   indicesGet.push_back( 6);
   indicesGet.push_back( 7);
   indicesGet.push_back( 8);
   indicesGet.push_back( 9);
   indicesGet.push_back( 10);
   indicesPut.push_back( 0);
   indicesPut.push_back( 1);
   indicesPut.push_back( 2);
   indicesPut.push_back( 3);
   indicesPut.push_back( 4);
   indicesPut.push_back( 5);
   indicesPut.push_back( 6);
   indicesPut.push_back( 7);
   indicesPut.push_back( 8);
   indicesPut.push_back( 9);
   indicesPut.push_back( 10);

   std::vector<double> dv(nVar);
   for (int ivar=0; ivar<nVar; ivar++) dv[ivar] = iv[indicesGet.at(ivar)];
   for (int ivar=0;ivar<11;ivar++) {
      double offset = fMin_1[cls][ivar];
      double scale  = 1.0/(fMax_1[cls][ivar]-fMin_1[cls][ivar]);
      iv[indicesPut.at(ivar)] = (dv[ivar]-offset)*scale * 2 - 1;
   }
}

//_______________________________________________________________________
inline void ReadMLPBNN::InitTransform_2()
{
   // Decorrelation transformation, initialisation
   fDecTF_2[0][0][0] = 3.17299784921;
   fDecTF_2[0][0][1] = -0.484276042646;
   fDecTF_2[0][0][2] = 0.0884194894785;
   fDecTF_2[0][0][3] = 0.0662995724491;
   fDecTF_2[0][0][4] = -0.00165789269036;
   fDecTF_2[0][0][5] = -0.00106932972554;
   fDecTF_2[0][0][6] = -0.0406033084621;
   fDecTF_2[0][0][7] = -0.0607812629855;
   fDecTF_2[0][0][8] = 0.0296326246794;
   fDecTF_2[0][0][9] = -0.11333993294;
   fDecTF_2[0][0][10] = -0.16025450864;
   fDecTF_2[0][1][0] = -0.484276042646;
   fDecTF_2[0][1][1] = 3.97911458184;
   fDecTF_2[0][1][2] = 0.0736820392442;
   fDecTF_2[0][1][3] = -0.0630370886434;
   fDecTF_2[0][1][4] = -0.00688835968048;
   fDecTF_2[0][1][5] = 0.032782138238;
   fDecTF_2[0][1][6] = 0.0168123879993;
   fDecTF_2[0][1][7] = 0.0179741190645;
   fDecTF_2[0][1][8] = 0.0214546402314;
   fDecTF_2[0][1][9] = -0.0317892659544;
   fDecTF_2[0][1][10] = -0.135778183705;
   fDecTF_2[0][2][0] = 0.0884194894785;
   fDecTF_2[0][2][1] = 0.0736820392442;
   fDecTF_2[0][2][2] = 6.63182378936;
   fDecTF_2[0][2][3] = -0.177906543834;
   fDecTF_2[0][2][4] = -0.786521668806;
   fDecTF_2[0][2][5] = 0.308538552218;
   fDecTF_2[0][2][6] = 0.586704615296;
   fDecTF_2[0][2][7] = 0.515992120973;
   fDecTF_2[0][2][8] = -0.0111580307625;
   fDecTF_2[0][2][9] = 0.0410508920149;
   fDecTF_2[0][2][10] = -0.000290530480353;
   fDecTF_2[0][3][0] = 0.0662995724491;
   fDecTF_2[0][3][1] = -0.0630370886434;
   fDecTF_2[0][3][2] = -0.177906543834;
   fDecTF_2[0][3][3] = 6.44317486484;
   fDecTF_2[0][3][4] = -1.89204127335;
   fDecTF_2[0][3][5] = -1.25949236174;
   fDecTF_2[0][3][6] = 1.09016621582;
   fDecTF_2[0][3][7] = 1.09405179588;
   fDecTF_2[0][3][8] = 5.0617050046;
   fDecTF_2[0][3][9] = -3.87681599445;
   fDecTF_2[0][3][10] = 0.0330626935337;
   fDecTF_2[0][4][0] = -0.00165789269036;
   fDecTF_2[0][4][1] = -0.00688835968048;
   fDecTF_2[0][4][2] = -0.786521668806;
   fDecTF_2[0][4][3] = -1.89204127335;
   fDecTF_2[0][4][4] = 10.0943570602;
   fDecTF_2[0][4][5] = -1.68997310925;
   fDecTF_2[0][4][6] = -3.10875226488;
   fDecTF_2[0][4][7] = -2.88085187927;
   fDecTF_2[0][4][8] = 0.00603788322459;
   fDecTF_2[0][4][9] = 0.149066378049;
   fDecTF_2[0][4][10] = 0.0789896842456;
   fDecTF_2[0][5][0] = -0.00106932972554;
   fDecTF_2[0][5][1] = 0.032782138238;
   fDecTF_2[0][5][2] = 0.308538552218;
   fDecTF_2[0][5][3] = -1.25949236174;
   fDecTF_2[0][5][4] = -1.68997310925;
   fDecTF_2[0][5][5] = 3.75417599853;
   fDecTF_2[0][5][6] = 0.563044980015;
   fDecTF_2[0][5][7] = 0.669021715179;
   fDecTF_2[0][5][8] = -0.889284440225;
   fDecTF_2[0][5][9] = 0.952000768245;
   fDecTF_2[0][5][10] = 0.177060949444;
   fDecTF_2[0][6][0] = -0.0406033084621;
   fDecTF_2[0][6][1] = 0.0168123879993;
   fDecTF_2[0][6][2] = 0.586704615296;
   fDecTF_2[0][6][3] = 1.09016621582;
   fDecTF_2[0][6][4] = -3.10875226488;
   fDecTF_2[0][6][5] = 0.563044980015;
   fDecTF_2[0][6][6] = 6.68958008749;
   fDecTF_2[0][6][7] = 0.815179012881;
   fDecTF_2[0][6][8] = -0.18403528531;
   fDecTF_2[0][6][9] = 0.0934138992881;
   fDecTF_2[0][6][10] = -0.00103719649336;
   fDecTF_2[0][7][0] = -0.0607812629855;
   fDecTF_2[0][7][1] = 0.0179741190645;
   fDecTF_2[0][7][2] = 0.515992120973;
   fDecTF_2[0][7][3] = 1.09405179588;
   fDecTF_2[0][7][4] = -2.88085187927;
   fDecTF_2[0][7][5] = 0.669021715179;
   fDecTF_2[0][7][6] = 0.815179012881;
   fDecTF_2[0][7][7] = 6.12700222504;
   fDecTF_2[0][7][8] = -0.143511215684;
   fDecTF_2[0][7][9] = 0.0282491506201;
   fDecTF_2[0][7][10] = 0.00192556140325;
   fDecTF_2[0][8][0] = 0.0296326246794;
   fDecTF_2[0][8][1] = 0.0214546402314;
   fDecTF_2[0][8][2] = -0.0111580307625;
   fDecTF_2[0][8][3] = 5.0617050046;
   fDecTF_2[0][8][4] = 0.00603788322459;
   fDecTF_2[0][8][5] = -0.889284440225;
   fDecTF_2[0][8][6] = -0.18403528531;
   fDecTF_2[0][8][7] = -0.143511215684;
   fDecTF_2[0][8][8] = 19.4742447939;
   fDecTF_2[0][8][9] = -14.785979572;
   fDecTF_2[0][8][10] = -0.0727048113953;
   fDecTF_2[0][9][0] = -0.11333993294;
   fDecTF_2[0][9][1] = -0.0317892659544;
   fDecTF_2[0][9][2] = 0.0410508920149;
   fDecTF_2[0][9][3] = -3.87681599445;
   fDecTF_2[0][9][4] = 0.149066378049;
   fDecTF_2[0][9][5] = 0.952000768245;
   fDecTF_2[0][9][6] = 0.0934138992881;
   fDecTF_2[0][9][7] = 0.0282491506201;
   fDecTF_2[0][9][8] = -14.785979572;
   fDecTF_2[0][9][9] = 20.2065705371;
   fDecTF_2[0][9][10] = -0.013377539858;
   fDecTF_2[0][10][0] = -0.16025450864;
   fDecTF_2[0][10][1] = -0.135778183705;
   fDecTF_2[0][10][2] = -0.000290530480353;
   fDecTF_2[0][10][3] = 0.0330626935337;
   fDecTF_2[0][10][4] = 0.0789896842456;
   fDecTF_2[0][10][5] = 0.177060949444;
   fDecTF_2[0][10][6] = -0.00103719649336;
   fDecTF_2[0][10][7] = 0.00192556140325;
   fDecTF_2[0][10][8] = -0.0727048113953;
   fDecTF_2[0][10][9] = -0.013377539858;
   fDecTF_2[0][10][10] = 4.4092551005;
   fDecTF_2[1][0][0] = 3.28481164051;
   fDecTF_2[1][0][1] = -0.49212370658;
   fDecTF_2[1][0][2] = 0.0949004709621;
   fDecTF_2[1][0][3] = -0.00762932484272;
   fDecTF_2[1][0][4] = 0.0441395534517;
   fDecTF_2[1][0][5] = -0.0292086131983;
   fDecTF_2[1][0][6] = 0.00508024222141;
   fDecTF_2[1][0][7] = -0.00811183257261;
   fDecTF_2[1][0][8] = 0.0206890143007;
   fDecTF_2[1][0][9] = -0.0513840619973;
   fDecTF_2[1][0][10] = -0.162116514376;
   fDecTF_2[1][1][0] = -0.49212370658;
   fDecTF_2[1][1][1] = 3.80467339574;
   fDecTF_2[1][1][2] = 0.081200841476;
   fDecTF_2[1][1][3] = -0.0612668012139;
   fDecTF_2[1][1][4] = -0.0154264584749;
   fDecTF_2[1][1][5] = 0.0164500100979;
   fDecTF_2[1][1][6] = 0.0128955713467;
   fDecTF_2[1][1][7] = -0.00292285003193;
   fDecTF_2[1][1][8] = -0.101041372904;
   fDecTF_2[1][1][9] = -0.353172559649;
   fDecTF_2[1][1][10] = -0.249403408691;
   fDecTF_2[1][2][0] = 0.0949004709621;
   fDecTF_2[1][2][1] = 0.081200841476;
   fDecTF_2[1][2][2] = 6.41490646276;
   fDecTF_2[1][2][3] = 0.284333234603;
   fDecTF_2[1][2][4] = -1.22270905234;
   fDecTF_2[1][2][5] = 0.331695595504;
   fDecTF_2[1][2][6] = 0.526401047727;
   fDecTF_2[1][2][7] = 0.368173827103;
   fDecTF_2[1][2][8] = -0.0263275194659;
   fDecTF_2[1][2][9] = 0.0306994966547;
   fDecTF_2[1][2][10] = 0.00330107784612;
   fDecTF_2[1][3][0] = -0.00762932484272;
   fDecTF_2[1][3][1] = -0.0612668012139;
   fDecTF_2[1][3][2] = 0.284333234603;
   fDecTF_2[1][3][3] = 5.53961336186;
   fDecTF_2[1][3][4] = -2.10646686031;
   fDecTF_2[1][3][5] = -0.70111916086;
   fDecTF_2[1][3][6] = 0.809711165571;
   fDecTF_2[1][3][7] = 0.566411812192;
   fDecTF_2[1][3][8] = 3.17041305775;
   fDecTF_2[1][3][9] = -2.89990440354;
   fDecTF_2[1][3][10] = 0.0193401278978;
   fDecTF_2[1][4][0] = 0.0441395534517;
   fDecTF_2[1][4][1] = -0.0154264584749;
   fDecTF_2[1][4][2] = -1.22270905234;
   fDecTF_2[1][4][3] = -2.10646686031;
   fDecTF_2[1][4][4] = 10.3517982551;
   fDecTF_2[1][4][5] = -2.25766791728;
   fDecTF_2[1][4][6] = -2.91928469258;
   fDecTF_2[1][4][7] = -2.44007562978;
   fDecTF_2[1][4][8] = 0.126082309304;
   fDecTF_2[1][4][9] = -0.0525037021936;
   fDecTF_2[1][4][10] = 0.0266131177758;
   fDecTF_2[1][5][0] = -0.0292086131983;
   fDecTF_2[1][5][1] = 0.0164500100979;
   fDecTF_2[1][5][2] = 0.331695595504;
   fDecTF_2[1][5][3] = -0.70111916086;
   fDecTF_2[1][5][4] = -2.25766791728;
   fDecTF_2[1][5][5] = 4.02045140179;
   fDecTF_2[1][5][6] = 0.473680942813;
   fDecTF_2[1][5][7] = 0.617138479768;
   fDecTF_2[1][5][8] = -0.606580863988;
   fDecTF_2[1][5][9] = 0.634518915389;
   fDecTF_2[1][5][10] = 0.0535677564006;
   fDecTF_2[1][6][0] = 0.00508024222141;
   fDecTF_2[1][6][1] = 0.0128955713467;
   fDecTF_2[1][6][2] = 0.526401047727;
   fDecTF_2[1][6][3] = 0.809711165571;
   fDecTF_2[1][6][4] = -2.91928469258;
   fDecTF_2[1][6][5] = 0.473680942813;
   fDecTF_2[1][6][6] = 6.79036999948;
   fDecTF_2[1][6][7] = 0.846145088877;
   fDecTF_2[1][6][8] = -0.081284260605;
   fDecTF_2[1][6][9] = 0.0987834027014;
   fDecTF_2[1][6][10] = -0.00210737921825;
   fDecTF_2[1][7][0] = -0.00811183257261;
   fDecTF_2[1][7][1] = -0.00292285003193;
   fDecTF_2[1][7][2] = 0.368173827103;
   fDecTF_2[1][7][3] = 0.566411812192;
   fDecTF_2[1][7][4] = -2.44007562978;
   fDecTF_2[1][7][5] = 0.617138479768;
   fDecTF_2[1][7][6] = 0.846145088877;
   fDecTF_2[1][7][7] = 6.18366155189;
   fDecTF_2[1][7][8] = -0.125090765115;
   fDecTF_2[1][7][9] = 0.0998316409486;
   fDecTF_2[1][7][10] = 0.00936179182123;
   fDecTF_2[1][8][0] = 0.0206890143007;
   fDecTF_2[1][8][1] = -0.101041372904;
   fDecTF_2[1][8][2] = -0.0263275194659;
   fDecTF_2[1][8][3] = 3.17041305775;
   fDecTF_2[1][8][4] = 0.126082309304;
   fDecTF_2[1][8][5] = -0.606580863988;
   fDecTF_2[1][8][6] = -0.081284260605;
   fDecTF_2[1][8][7] = -0.125090765115;
   fDecTF_2[1][8][8] = 13.0339770381;
   fDecTF_2[1][8][9] = -9.73999664158;
   fDecTF_2[1][8][10] = -0.343882497559;
   fDecTF_2[1][9][0] = -0.0513840619973;
   fDecTF_2[1][9][1] = -0.353172559649;
   fDecTF_2[1][9][2] = 0.0306994966547;
   fDecTF_2[1][9][3] = -2.89990440354;
   fDecTF_2[1][9][4] = -0.0525037021936;
   fDecTF_2[1][9][5] = 0.634518915389;
   fDecTF_2[1][9][6] = 0.0987834027014;
   fDecTF_2[1][9][7] = 0.0998316409486;
   fDecTF_2[1][9][8] = -9.73999664158;
   fDecTF_2[1][9][9] = 13.0058512991;
   fDecTF_2[1][9][10] = -0.262251907821;
   fDecTF_2[1][10][0] = -0.162116514376;
   fDecTF_2[1][10][1] = -0.249403408691;
   fDecTF_2[1][10][2] = 0.00330107784612;
   fDecTF_2[1][10][3] = 0.0193401278978;
   fDecTF_2[1][10][4] = 0.0266131177758;
   fDecTF_2[1][10][5] = 0.0535677564006;
   fDecTF_2[1][10][6] = -0.00210737921825;
   fDecTF_2[1][10][7] = 0.00936179182123;
   fDecTF_2[1][10][8] = -0.343882497559;
   fDecTF_2[1][10][9] = -0.262251907821;
   fDecTF_2[1][10][10] = 2.62166513717;
   fDecTF_2[2][0][0] = 3.19528784371;
   fDecTF_2[2][0][1] = -0.491859913712;
   fDecTF_2[2][0][2] = 0.113937877245;
   fDecTF_2[2][0][3] = 0.0532147856143;
   fDecTF_2[2][0][4] = -0.024806273057;
   fDecTF_2[2][0][5] = 0.00809857083368;
   fDecTF_2[2][0][6] = -0.0407150215483;
   fDecTF_2[2][0][7] = -0.0608731597809;
   fDecTF_2[2][0][8] = -0.0262155365234;
   fDecTF_2[2][0][9] = -0.105552937305;
   fDecTF_2[2][0][10] = -0.210120802089;
   fDecTF_2[2][1][0] = -0.491859913712;
   fDecTF_2[2][1][1] = 3.87653169673;
   fDecTF_2[2][1][2] = 0.0773726956602;
   fDecTF_2[2][1][3] = -0.0762862700749;
   fDecTF_2[2][1][4] = -0.013554121147;
   fDecTF_2[2][1][5] = 0.0221567739954;
   fDecTF_2[2][1][6] = 0.014456195427;
   fDecTF_2[2][1][7] = 0.00711376921919;
   fDecTF_2[2][1][8] = -0.0720215272978;
   fDecTF_2[2][1][9] = -0.257650695735;
   fDecTF_2[2][1][10] = -0.239775819663;
   fDecTF_2[2][2][0] = 0.113937877245;
   fDecTF_2[2][2][1] = 0.0773726956602;
   fDecTF_2[2][2][2] = 6.47603766067;
   fDecTF_2[2][2][3] = 0.0374793546751;
   fDecTF_2[2][2][4] = -0.942570571427;
   fDecTF_2[2][2][5] = 0.277426064227;
   fDecTF_2[2][2][6] = 0.581566307898;
   fDecTF_2[2][2][7] = 0.479044359754;
   fDecTF_2[2][2][8] = 0.0130023813181;
   fDecTF_2[2][2][9] = 0.0736337234526;
   fDecTF_2[2][2][10] = 0.0300619464965;
   fDecTF_2[2][3][0] = 0.0532147856143;
   fDecTF_2[2][3][1] = -0.0762862700749;
   fDecTF_2[2][3][2] = 0.0374793546751;
   fDecTF_2[2][3][3] = 5.80596030125;
   fDecTF_2[2][3][4] = -1.90468754867;
   fDecTF_2[2][3][5] = -0.996968868569;
   fDecTF_2[2][3][6] = 0.968272440102;
   fDecTF_2[2][3][7] = 0.848077724469;
   fDecTF_2[2][3][8] = 3.85170645326;
   fDecTF_2[2][3][9] = -3.22967589004;
   fDecTF_2[2][3][10] = 0.0255044514813;
   fDecTF_2[2][4][0] = -0.024806273057;
   fDecTF_2[2][4][1] = -0.013554121147;
   fDecTF_2[2][4][2] = -0.942570571427;
   fDecTF_2[2][4][3] = -1.90468754867;
   fDecTF_2[2][4][4] = 10.0282595252;
   fDecTF_2[2][4][5] = -1.89657325113;
   fDecTF_2[2][4][6] = -3.05172171964;
   fDecTF_2[2][4][7] = -2.71067670071;
   fDecTF_2[2][4][8] = 0.0143182622269;
   fDecTF_2[2][4][9] = -0.0533038896686;
   fDecTF_2[2][4][10] = -0.0254141077878;
   fDecTF_2[2][5][0] = 0.00809857083368;
   fDecTF_2[2][5][1] = 0.0221567739954;
   fDecTF_2[2][5][2] = 0.277426064227;
   fDecTF_2[2][5][3] = -0.996968868569;
   fDecTF_2[2][5][4] = -1.89657325113;
   fDecTF_2[2][5][5] = 3.83126086812;
   fDecTF_2[2][5][6] = 0.546698865717;
   fDecTF_2[2][5][7] = 0.683318162289;
   fDecTF_2[2][5][8] = -0.674258535639;
   fDecTF_2[2][5][9] = 0.777614014445;
   fDecTF_2[2][5][10] = 0.115582630566;
   fDecTF_2[2][6][0] = -0.0407150215483;
   fDecTF_2[2][6][1] = 0.014456195427;
   fDecTF_2[2][6][2] = 0.581566307898;
   fDecTF_2[2][6][3] = 0.968272440102;
   fDecTF_2[2][6][4] = -3.05172171964;
   fDecTF_2[2][6][5] = 0.546698865717;
   fDecTF_2[2][6][6] = 6.71241832151;
   fDecTF_2[2][6][7] = 0.796712002075;
   fDecTF_2[2][6][8] = -0.15537121841;
   fDecTF_2[2][6][9] = 0.0663012135385;
   fDecTF_2[2][6][10] = -0.030083174486;
   fDecTF_2[2][7][0] = -0.0608731597809;
   fDecTF_2[2][7][1] = 0.00711376921919;
   fDecTF_2[2][7][2] = 0.479044359754;
   fDecTF_2[2][7][3] = 0.848077724469;
   fDecTF_2[2][7][4] = -2.71067670071;
   fDecTF_2[2][7][5] = 0.683318162289;
   fDecTF_2[2][7][6] = 0.796712002075;
   fDecTF_2[2][7][7] = 6.10894728734;
   fDecTF_2[2][7][8] = -0.171051629017;
   fDecTF_2[2][7][9] = 0.0323230228609;
   fDecTF_2[2][7][10] = -0.0239884488878;
   fDecTF_2[2][8][0] = -0.0262155365234;
   fDecTF_2[2][8][1] = -0.0720215272978;
   fDecTF_2[2][8][2] = 0.0130023813181;
   fDecTF_2[2][8][3] = 3.85170645326;
   fDecTF_2[2][8][4] = 0.0143182622269;
   fDecTF_2[2][8][5] = -0.674258535639;
   fDecTF_2[2][8][6] = -0.15537121841;
   fDecTF_2[2][8][7] = -0.171051629017;
   fDecTF_2[2][8][8] = 15.193576366;
   fDecTF_2[2][8][9] = -11.5570989362;
   fDecTF_2[2][8][10] = -0.402081059098;
   fDecTF_2[2][9][0] = -0.105552937305;
   fDecTF_2[2][9][1] = -0.257650695735;
   fDecTF_2[2][9][2] = 0.0736337234526;
   fDecTF_2[2][9][3] = -3.22967589004;
   fDecTF_2[2][9][4] = -0.0533038896686;
   fDecTF_2[2][9][5] = 0.777614014445;
   fDecTF_2[2][9][6] = 0.0663012135385;
   fDecTF_2[2][9][7] = 0.0323230228609;
   fDecTF_2[2][9][8] = -11.5570989362;
   fDecTF_2[2][9][9] = 15.3549752745;
   fDecTF_2[2][9][10] = -0.308583569324;
   fDecTF_2[2][10][0] = -0.210120802089;
   fDecTF_2[2][10][1] = -0.239775819663;
   fDecTF_2[2][10][2] = 0.0300619464965;
   fDecTF_2[2][10][3] = 0.0255044514813;
   fDecTF_2[2][10][4] = -0.0254141077878;
   fDecTF_2[2][10][5] = 0.115582630566;
   fDecTF_2[2][10][6] = -0.030083174486;
   fDecTF_2[2][10][7] = -0.0239884488878;
   fDecTF_2[2][10][8] = -0.402081059098;
   fDecTF_2[2][10][9] = -0.308583569324;
   fDecTF_2[2][10][10] = 3.05735990717;
}

//_______________________________________________________________________
inline void ReadMLPBNN::Transform_2( std::vector<double>& iv, int cls) const
{
   // Decorrelation transformation
   if (cls < 0 || cls > 2) {
       if (2 > 1 ) cls = 2;
       else cls = 2;
   }

   // define the indices of the variables which are transformed by this transformation
   std::vector<int> indicesGet;
   std::vector<int> indicesPut;

   indicesGet.push_back( 0);
   indicesGet.push_back( 1);
   indicesGet.push_back( 2);
   indicesGet.push_back( 3);
   indicesGet.push_back( 4);
   indicesGet.push_back( 5);
   indicesGet.push_back( 6);
   indicesGet.push_back( 7);
   indicesGet.push_back( 8);
   indicesGet.push_back( 9);
   indicesGet.push_back( 10);
   indicesPut.push_back( 0);
   indicesPut.push_back( 1);
   indicesPut.push_back( 2);
   indicesPut.push_back( 3);
   indicesPut.push_back( 4);
   indicesPut.push_back( 5);
   indicesPut.push_back( 6);
   indicesPut.push_back( 7);
   indicesPut.push_back( 8);
   indicesPut.push_back( 9);
   indicesPut.push_back( 10);

   std::vector<double> tv;
   for (int i=0; i<11;i++) {
      double v = 0;
      for (int j=0; j<11; j++)
         v += iv[indicesGet.at(j)] * fDecTF_2[cls][i][j];
      tv.push_back(v);
   }
   for (int i=0; i<11;i++) iv[indicesPut.at(i)] = tv[i];
}

//_______________________________________________________________________
inline void ReadMLPBNN::InitTransform()
{
   InitTransform_1();
   InitTransform_2();
}

//_______________________________________________________________________
inline void ReadMLPBNN::Transform( std::vector<double>& iv, int sigOrBgd ) const
{
   Transform_1( iv, sigOrBgd );
   Transform_2( iv, sigOrBgd );
}

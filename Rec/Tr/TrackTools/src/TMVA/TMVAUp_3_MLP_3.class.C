// Class: ReadMLP_3
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP_3
TMVA Release   : 4.2.0         [262656]
ROOT Release   : 5.34/20       [336404]
Creator        : pseyfert
Date           : Wed Dec 31 19:10:11 2014
Host           : Linux robusta 3.2.0-4-amd64 #1 SMP Debian 3.2.60-1+deb7u3 x86_64 GNU/Linux
Dir            : /home/pseyfert/phd/dropbox/tracking/2014-12-24
Training events: 71948
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
NCycles: "600" [Number of training cycles]
HiddenLayers: "N+5" [Specification of hidden layer architecture]
NeuronType: "tanh" [Neuron activation function type]
EstimatorType: "CE" [MSE (Mean Square Estimator) for Gaussian Likelihood or CE(Cross-Entropy) for Bernoulli Likelihood]
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
VarTransform: "N" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
H: "False" [Print method-specific help message]
CreateMVAPdfs: "True" [Create PDFs for classifier outputs (signal and background)]
TestRate: "5" [Test for overtraining performed at each #th epochs]
UseRegulator: "False" [Use regulator to avoid over-training]
# Default:
RandomSeed: "1" [Random seed for initial synapse weights (0 means unique seed for each run; default value '1')]
NeuronInputType: "sum" [Neuron input function type]
VerbosityLevel: "Default" [Verbosity level]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
TrainingMethod: "BP" [Train with Back-Propagation (BP), BFGS Algorithm (BFGS), or Genetic Algorithm (GA - slower and worse)]
LearningRate: "2.000000e-02" [ANN learning rate parameter]
DecayRate: "1.000000e-02" [Decay rate for learning parameter]
EpochMonitoring: "False" [Provide epoch-wise monitoring plots according to TestRate (caution: causes big ROOT output file!)]
Sampling: "1.000000e+00" [Only 'Sampling' (randomly selected) events are trained each epoch]
SamplingEpoch: "1.000000e+00" [Sampling is used for the first 'SamplingEpoch' epochs, afterwards, all events are taken for training]
SamplingImportance: "1.000000e+00" [ The sampling weights of events in epochs which successful (worse estimator than before) are multiplied with SamplingImportance, else they are divided.]
SamplingTraining: "True" [The training sample is sampled]
SamplingTesting: "False" [The testing sample is sampled]
ResetStep: "50" [How often BFGS should reset history]
Tau: "3.000000e+00" [LineSearch "size step"]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
ConvergenceImprove: "1.000000e-30" [Minimum improvement which counts as improvement (<0 means automatic convergence check is turned off)]
ConvergenceTests: "-1" [Number of steps (without improvement) required for convergence (<0 means automatic convergence check is turned off)]
UpdateLimit: "10000" [Maximum times of regulator update]
CalculateErrors: "False" [Calculates inverse Hessian matrix at the end of the training to be able to calculate the uncertainties of an MVA value]
WeightRange: "1.000000e+00" [Take the events for the estimator calculations from small deviations from the desired value to large deviations only over the weight range]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 17
UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP                                          'F'    [3,21]
UpgradeGhostInfo_expVP        UpgradeGhostInfo_expVP        UpgradeGhostInfo_expVP        UpgradeGhostInfo_expVP                                          'F'    [1,26]
UpgradeGhostInfo_FitVeloChi2  UpgradeGhostInfo_FitVeloChi2  UpgradeGhostInfo_FitVeloChi2  UpgradeGhostInfo_FitVeloChi2                                    'F'    [4.60151944326e-10,103.770103455]
UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF                                    'F'    [-1,37]
UpgradeGhostInfo_obsFT        UpgradeGhostInfo_obsFT        UpgradeGhostInfo_obsFT        UpgradeGhostInfo_obsFT                                          'F'    [10,14]
UpgradeGhostInfo_expFTHitExpectation UpgradeGhostInfo_expFTHitExpectation UpgradeGhostInfo_expFTHitExpectation UpgradeGhostInfo_expFTHitExpectation                                          'F'    [0,12]
UpgradeGhostInfo_FitTChi2     UpgradeGhostInfo_FitTChi2     UpgradeGhostInfo_FitTChi2     UpgradeGhostInfo_FitTChi2                                       'F'    [0.00728893233463,42.1457099915]
UpgradeGhostInfo_FitTNDoF     UpgradeGhostInfo_FitTNDoF     UpgradeGhostInfo_FitTNDoF     UpgradeGhostInfo_FitTNDoF                                       'F'    [3,9]
UpgradeGhostInfo_obsUT        UpgradeGhostInfo_obsUT        UpgradeGhostInfo_obsUT        UpgradeGhostInfo_obsUT                                          'F'    [0,8]
UpgradeGhostInfo_expUTHitExpectation UpgradeGhostInfo_expUTHitExpectation UpgradeGhostInfo_expUTHitExpectation UpgradeGhostInfo_expUTHitExpectation                                          'F'    [0,8]
UpgradeGhostInfo_FitMatchChi2 UpgradeGhostInfo_FitMatchChi2 UpgradeGhostInfo_FitMatchChi2 UpgradeGhostInfo_FitMatchChi2                                   'F'    [0.0505929067731,105.047515869]
UpgradeGhostInfo_UToutlier    UpgradeGhostInfo_UToutlier    UpgradeGhostInfo_UToutlier    UpgradeGhostInfo_UToutlier                                      'F'    [0,2]
UpgradeGhostInfo_veloHits     UpgradeGhostInfo_veloHits     UpgradeGhostInfo_veloHits     UpgradeGhostInfo_veloHits                                       'F'    [223,6680]
UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits                                         'F'    [143,4409]
TRACK_CHI2                    TRACK_CHI2                    TRACK_CHI2                    TRACK_CHI2                                                      'F'    [0.5633071661,128.49848938]
TRACK_PT                      TRACK_PT                      TRACK_PT                      TRACK_PT                                                        'F'    [12.2846269608,127576.226562]
TRACK_ETA                     TRACK_ETA                     TRACK_ETA                     TRACK_ETA                                                       'F'    [1.52242255211,6.96952486038]
NSpec 4
UpgradeGhostInfo_ghostCat     UpgradeGhostInfo_ghostCat     UpgradeGhostInfo_ghostCat     F                                                               'F'    [10,21]
TRACK_Type                    TRACK_Type                    TRACK_Type                    F                                                               'F'    [3,3]
UpgradeGhostInfo_MCPID        UpgradeGhostInfo_MCPID        UpgradeGhostInfo_MCPID        F                                                               'F'    [-3312,3222]
PP_TrackHistory               PP_TrackHistory               PP_TrackHistory               F                                                               'F'    [30,32]


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadMLP_3 : public IClassifierReader {

 public:

   // constructor
   ReadMLP_3( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadMLP_3" ),
        fNvars( 17 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "UpgradeGhostInfo_obsVP", "UpgradeGhostInfo_expVP", "UpgradeGhostInfo_FitVeloChi2", "UpgradeGhostInfo_FitVeloNDoF", "UpgradeGhostInfo_obsFT", "UpgradeGhostInfo_expFTHitExpectation", "UpgradeGhostInfo_FitTChi2", "UpgradeGhostInfo_FitTNDoF", "UpgradeGhostInfo_obsUT", "UpgradeGhostInfo_expUTHitExpectation", "UpgradeGhostInfo_FitMatchChi2", "UpgradeGhostInfo_UToutlier", "UpgradeGhostInfo_veloHits", "UpgradeGhostInfo_utHits", "TRACK_CHI2", "TRACK_PT", "TRACK_ETA" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = -1;
      fVmax[0] = 1;
      fVmin[1] = -1;
      fVmax[1] = 1;
      fVmin[2] = -1;
      fVmax[2] = 1;
      fVmin[3] = -1;
      fVmax[3] = 1;
      fVmin[4] = -1;
      fVmax[4] = 1;
      fVmin[5] = -1;
      fVmax[5] = 1;
      fVmin[6] = -1;
      fVmax[6] = 1;
      fVmin[7] = -1;
      fVmax[7] = 1;
      fVmin[8] = -1;
      fVmax[8] = 1;
      fVmin[9] = -1;
      fVmax[9] = 1;
      fVmin[10] = -1;
      fVmax[10] = 1;
      fVmin[11] = -1;
      fVmax[11] = 1;
      fVmin[12] = -1;
      fVmax[12] = 1;
      fVmin[13] = -1;
      fVmax[13] = 1;
      fVmin[14] = -1;
      fVmax[14] = 1;
      fVmin[15] = -1;
      fVmax[15] = 1;
      fVmin[16] = -1;
      fVmax[16] = 1;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';
      fType[13] = 'F';
      fType[14] = 'F';
      fType[15] = 'F';
      fType[16] = 'F';

      // initialize constants
      Initialize();

      // initialize transformation
      InitTransform();
   }

   // destructor
   virtual ~ReadMLP_3() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // input variable transformation

   double fMin_1[3][17];
   double fMax_1[3][17];
   void InitTransform_1();
   void Transform_1( std::vector<double> & iv, int sigOrBgd ) const;
   void InitTransform();
   void Transform( std::vector<double> & iv, int sigOrBgd ) const;

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[17];
   double fVmax[17];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[17];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)

   double ActivationFnc(double x) const;
   double OutputActivationFnc(double x) const;

   int fLayers;
   int fLayerSize[3];
   double fWeightMatrix0to1[23][18];   // weight matrix from layer 0 to 1
   double fWeightMatrix1to2[1][23];   // weight matrix from layer 1 to 2

   double * fWeights[3];
};

inline void ReadMLP_3::Initialize()
{
   // build network structure
   fLayers = 3;
   fLayerSize[0] = 18; fWeights[0] = new double[18]; 
   fLayerSize[1] = 23; fWeights[1] = new double[23]; 
   fLayerSize[2] = 1; fWeights[2] = new double[1]; 
   // weight matrix from layer 0 to 1
   fWeightMatrix0to1[0][0] = -0.0776383345769885;
   fWeightMatrix0to1[1][0] = 1.85875695558898;
   fWeightMatrix0to1[2][0] = -1.39279690781885;
   fWeightMatrix0to1[3][0] = 2.31788908080701;
   fWeightMatrix0to1[4][0] = -3.811388168909;
   fWeightMatrix0to1[5][0] = 0.809235012482415;
   fWeightMatrix0to1[6][0] = -1.93753182117988;
   fWeightMatrix0to1[7][0] = 1.70793770508146;
   fWeightMatrix0to1[8][0] = -0.633163364432882;
   fWeightMatrix0to1[9][0] = 0.20350221992754;
   fWeightMatrix0to1[10][0] = -1.81121499325374;
   fWeightMatrix0to1[11][0] = 0.0143979871167766;
   fWeightMatrix0to1[12][0] = 2.30616820540971;
   fWeightMatrix0to1[13][0] = -0.425629987422537;
   fWeightMatrix0to1[14][0] = -0.0612136568198523;
   fWeightMatrix0to1[15][0] = -0.82894889305834;
   fWeightMatrix0to1[16][0] = -1.11867495976394;
   fWeightMatrix0to1[17][0] = 1.54110724661946;
   fWeightMatrix0to1[18][0] = 5.05822069154615;
   fWeightMatrix0to1[19][0] = 0.159205340181261;
   fWeightMatrix0to1[20][0] = -6.28914031027818;
   fWeightMatrix0to1[21][0] = -0.0972072426940535;
   fWeightMatrix0to1[0][1] = 0.239326303265387;
   fWeightMatrix0to1[1][1] = 0.538030892134972;
   fWeightMatrix0to1[2][1] = 1.76095479835217;
   fWeightMatrix0to1[3][1] = 2.18225639569125;
   fWeightMatrix0to1[4][1] = 3.47326769590812;
   fWeightMatrix0to1[5][1] = 0.845206978715781;
   fWeightMatrix0to1[6][1] = -4.84627366507262;
   fWeightMatrix0to1[7][1] = -0.0507934645301319;
   fWeightMatrix0to1[8][1] = 1.29049001659668;
   fWeightMatrix0to1[9][1] = 2.72819232745953;
   fWeightMatrix0to1[10][1] = -0.598920556453899;
   fWeightMatrix0to1[11][1] = -0.111346958860694;
   fWeightMatrix0to1[12][1] = 1.44993816324702;
   fWeightMatrix0to1[13][1] = -0.270904117547435;
   fWeightMatrix0to1[14][1] = 2.62389033588584;
   fWeightMatrix0to1[15][1] = 0.205332804688683;
   fWeightMatrix0to1[16][1] = -1.04827192494371;
   fWeightMatrix0to1[17][1] = 1.03886410782591;
   fWeightMatrix0to1[18][1] = 4.16094268708779;
   fWeightMatrix0to1[19][1] = 0.411601053606199;
   fWeightMatrix0to1[20][1] = -1.99175274432259;
   fWeightMatrix0to1[21][1] = 0.885111828505319;
   fWeightMatrix0to1[0][2] = 0.395477625957776;
   fWeightMatrix0to1[1][2] = -0.957179958100174;
   fWeightMatrix0to1[2][2] = -0.513321428142281;
   fWeightMatrix0to1[3][2] = 1.80697258372827;
   fWeightMatrix0to1[4][2] = 1.04675754778152;
   fWeightMatrix0to1[5][2] = 3.16718726072208;
   fWeightMatrix0to1[6][2] = 4.91651457597019;
   fWeightMatrix0to1[7][2] = 1.68538710922591;
   fWeightMatrix0to1[8][2] = -1.74338983017184;
   fWeightMatrix0to1[9][2] = 1.00461257095125;
   fWeightMatrix0to1[10][2] = -1.3578360737431;
   fWeightMatrix0to1[11][2] = 2.21128589552869;
   fWeightMatrix0to1[12][2] = -4.11016016671883;
   fWeightMatrix0to1[13][2] = -1.78279735600609;
   fWeightMatrix0to1[14][2] = -0.560847277071744;
   fWeightMatrix0to1[15][2] = 3.13500854686062;
   fWeightMatrix0to1[16][2] = 0.594813500783742;
   fWeightMatrix0to1[17][2] = 1.44566667952192;
   fWeightMatrix0to1[18][2] = 0.539998651213878;
   fWeightMatrix0to1[19][2] = 1.24504508633602;
   fWeightMatrix0to1[20][2] = 2.92391377187283;
   fWeightMatrix0to1[21][2] = 0.00563377946007922;
   fWeightMatrix0to1[0][3] = 1.09085745117096;
   fWeightMatrix0to1[1][3] = 4.76717768644797;
   fWeightMatrix0to1[2][3] = -0.193971356696291;
   fWeightMatrix0to1[3][3] = -4.29691792422339;
   fWeightMatrix0to1[4][3] = 1.33109534049606;
   fWeightMatrix0to1[5][3] = -3.16784794220421;
   fWeightMatrix0to1[6][3] = 3.11991046155092;
   fWeightMatrix0to1[7][3] = 0.84089339471331;
   fWeightMatrix0to1[8][3] = 2.01773858991121;
   fWeightMatrix0to1[9][3] = 0.826283549073847;
   fWeightMatrix0to1[10][3] = -1.4182682689185;
   fWeightMatrix0to1[11][3] = 0.0755402638469486;
   fWeightMatrix0to1[12][3] = -3.74156428178563;
   fWeightMatrix0to1[13][3] = 0.521777886246204;
   fWeightMatrix0to1[14][3] = -1.25641842159564;
   fWeightMatrix0to1[15][3] = -0.933527168724492;
   fWeightMatrix0to1[16][3] = 1.63723859178725;
   fWeightMatrix0to1[17][3] = -1.05450531337283;
   fWeightMatrix0to1[18][3] = -10.9733908321504;
   fWeightMatrix0to1[19][3] = -1.22292620626566;
   fWeightMatrix0to1[20][3] = 8.48846931585607;
   fWeightMatrix0to1[21][3] = -0.351638100224681;
   fWeightMatrix0to1[0][4] = -0.132423857753567;
   fWeightMatrix0to1[1][4] = -0.401382137988386;
   fWeightMatrix0to1[2][4] = 1.61964061789317;
   fWeightMatrix0to1[3][4] = -0.277740548938528;
   fWeightMatrix0to1[4][4] = 1.10398771031187;
   fWeightMatrix0to1[5][4] = 0.0094174923428213;
   fWeightMatrix0to1[6][4] = -2.2195289109592;
   fWeightMatrix0to1[7][4] = 1.34374183689927;
   fWeightMatrix0to1[8][4] = -0.0262182496006132;
   fWeightMatrix0to1[9][4] = -0.749805258517649;
   fWeightMatrix0to1[10][4] = -2.04088382682064;
   fWeightMatrix0to1[11][4] = 0.0432132649039175;
   fWeightMatrix0to1[12][4] = -0.384220806125279;
   fWeightMatrix0to1[13][4] = -1.6843483904507;
   fWeightMatrix0to1[14][4] = 0.0355255049166005;
   fWeightMatrix0to1[15][4] = 0.813821321155465;
   fWeightMatrix0to1[16][4] = -1.01415646245181;
   fWeightMatrix0to1[17][4] = 1.83323950797192;
   fWeightMatrix0to1[18][4] = -0.0309288316742754;
   fWeightMatrix0to1[19][4] = -1.41488995698504;
   fWeightMatrix0to1[20][4] = -0.18231738254148;
   fWeightMatrix0to1[21][4] = 0.91120417293886;
   fWeightMatrix0to1[0][5] = -3.26159354459042;
   fWeightMatrix0to1[1][5] = 1.43881798203531;
   fWeightMatrix0to1[2][5] = -1.17211418562706;
   fWeightMatrix0to1[3][5] = -0.262933155059968;
   fWeightMatrix0to1[4][5] = -0.00658954339799877;
   fWeightMatrix0to1[5][5] = 0.377368362490902;
   fWeightMatrix0to1[6][5] = 0.808777589797852;
   fWeightMatrix0to1[7][5] = -1.1912812359923;
   fWeightMatrix0to1[8][5] = 0.811784461152817;
   fWeightMatrix0to1[9][5] = -0.642933238115466;
   fWeightMatrix0to1[10][5] = -0.901961524161118;
   fWeightMatrix0to1[11][5] = 0.130501723537043;
   fWeightMatrix0to1[12][5] = -1.59204359133896;
   fWeightMatrix0to1[13][5] = 1.84846834500472;
   fWeightMatrix0to1[14][5] = 1.34648066227592;
   fWeightMatrix0to1[15][5] = 0.0130997379537123;
   fWeightMatrix0to1[16][5] = 0.215303259269272;
   fWeightMatrix0to1[17][5] = -0.538917024899162;
   fWeightMatrix0to1[18][5] = -2.24415334427934;
   fWeightMatrix0to1[19][5] = 1.65065492429059;
   fWeightMatrix0to1[20][5] = 0.479873445136045;
   fWeightMatrix0to1[21][5] = -1.08591421185689;
   fWeightMatrix0to1[0][6] = 1.24933099191278;
   fWeightMatrix0to1[1][6] = 0.332690327810099;
   fWeightMatrix0to1[2][6] = -3.30003249893459;
   fWeightMatrix0to1[3][6] = -0.160787533586845;
   fWeightMatrix0to1[4][6] = 1.59298295072611;
   fWeightMatrix0to1[5][6] = -0.229431717475391;
   fWeightMatrix0to1[6][6] = -1.86170269108266;
   fWeightMatrix0to1[7][6] = 2.1121400706879;
   fWeightMatrix0to1[8][6] = 3.69639067971697;
   fWeightMatrix0to1[9][6] = -0.383419698501481;
   fWeightMatrix0to1[10][6] = -1.56277176640978;
   fWeightMatrix0to1[11][6] = -0.192717875704005;
   fWeightMatrix0to1[12][6] = -1.5310994203036;
   fWeightMatrix0to1[13][6] = 1.49824779863088;
   fWeightMatrix0to1[14][6] = -0.622621479396843;
   fWeightMatrix0to1[15][6] = -1.27475772140333;
   fWeightMatrix0to1[16][6] = -1.68576561275051;
   fWeightMatrix0to1[17][6] = 1.08665210816774;
   fWeightMatrix0to1[18][6] = -2.17325170960123;
   fWeightMatrix0to1[19][6] = 1.2049038424498;
   fWeightMatrix0to1[20][6] = 0.843398981260841;
   fWeightMatrix0to1[21][6] = -0.252372105391373;
   fWeightMatrix0to1[0][7] = -0.345281813217533;
   fWeightMatrix0to1[1][7] = 0.706487526838687;
   fWeightMatrix0to1[2][7] = 2.03420588333162;
   fWeightMatrix0to1[3][7] = 0.2602383684054;
   fWeightMatrix0to1[4][7] = -0.428591586737712;
   fWeightMatrix0to1[5][7] = -0.369701656111735;
   fWeightMatrix0to1[6][7] = 3.24096680324023;
   fWeightMatrix0to1[7][7] = 0.275493889992961;
   fWeightMatrix0to1[8][7] = -0.23179632824137;
   fWeightMatrix0to1[9][7] = 1.4041336289138;
   fWeightMatrix0to1[10][7] = 1.16569723815822;
   fWeightMatrix0to1[11][7] = 0.0510019539829567;
   fWeightMatrix0to1[12][7] = 1.22077192679685;
   fWeightMatrix0to1[13][7] = 1.06772435064661;
   fWeightMatrix0to1[14][7] = -0.154706606453873;
   fWeightMatrix0to1[15][7] = -1.43778524268384;
   fWeightMatrix0to1[16][7] = 1.43068277271164;
   fWeightMatrix0to1[17][7] = 1.29071257069884;
   fWeightMatrix0to1[18][7] = 0.708544460563832;
   fWeightMatrix0to1[19][7] = 1.2550359485728;
   fWeightMatrix0to1[20][7] = 0.228992602575356;
   fWeightMatrix0to1[21][7] = -1.10027897230168;
   fWeightMatrix0to1[0][8] = 0.212685834713327;
   fWeightMatrix0to1[1][8] = -0.797694913813391;
   fWeightMatrix0to1[2][8] = 0.164985427282289;
   fWeightMatrix0to1[3][8] = -0.086049264583487;
   fWeightMatrix0to1[4][8] = -0.221416791614132;
   fWeightMatrix0to1[5][8] = -0.326294087309536;
   fWeightMatrix0to1[6][8] = 0.819070085306203;
   fWeightMatrix0to1[7][8] = -1.78545914645042;
   fWeightMatrix0to1[8][8] = 0.235161992572044;
   fWeightMatrix0to1[9][8] = -0.227596820783252;
   fWeightMatrix0to1[10][8] = -1.27229826617621;
   fWeightMatrix0to1[11][8] = 9.16582223078061;
   fWeightMatrix0to1[12][8] = -3.22231575681067;
   fWeightMatrix0to1[13][8] = -0.453920930374947;
   fWeightMatrix0to1[14][8] = -4.3949443729427;
   fWeightMatrix0to1[15][8] = -0.331343070560992;
   fWeightMatrix0to1[16][8] = 1.68090820618975;
   fWeightMatrix0to1[17][8] = 0.658559665874566;
   fWeightMatrix0to1[18][8] = -0.7478597425396;
   fWeightMatrix0to1[19][8] = 0.199428466523608;
   fWeightMatrix0to1[20][8] = 0.404488021332437;
   fWeightMatrix0to1[21][8] = 0.993124308160091;
   fWeightMatrix0to1[0][9] = -0.231321708725249;
   fWeightMatrix0to1[1][9] = -1.0448815416538;
   fWeightMatrix0to1[2][9] = -0.209890448966675;
   fWeightMatrix0to1[3][9] = 0.68616743079334;
   fWeightMatrix0to1[4][9] = 1.52961023942054;
   fWeightMatrix0to1[5][9] = -0.416041633481664;
   fWeightMatrix0to1[6][9] = 1.35072382654251;
   fWeightMatrix0to1[7][9] = 0.738665925090958;
   fWeightMatrix0to1[8][9] = -1.22624096935735;
   fWeightMatrix0to1[9][9] = -0.251778779950799;
   fWeightMatrix0to1[10][9] = 0.938859324178348;
   fWeightMatrix0to1[11][9] = -1.61568850554531;
   fWeightMatrix0to1[12][9] = 3.042950218561;
   fWeightMatrix0to1[13][9] = -0.123044683333827;
   fWeightMatrix0to1[14][9] = -1.95680500852753;
   fWeightMatrix0to1[15][9] = -1.09136404239448;
   fWeightMatrix0to1[16][9] = 0.355460117102409;
   fWeightMatrix0to1[17][9] = 1.23120266162161;
   fWeightMatrix0to1[18][9] = 0.402569152929377;
   fWeightMatrix0to1[19][9] = 0.530290663825324;
   fWeightMatrix0to1[20][9] = 0.184488560674474;
   fWeightMatrix0to1[21][9] = -1.29270961492125;
   fWeightMatrix0to1[0][10] = -0.745810718398886;
   fWeightMatrix0to1[1][10] = -1.33132553543392;
   fWeightMatrix0to1[2][10] = -1.44176521832414;
   fWeightMatrix0to1[3][10] = 4.86162289787386;
   fWeightMatrix0to1[4][10] = 2.79462358908735;
   fWeightMatrix0to1[5][10] = -0.149332763402422;
   fWeightMatrix0to1[6][10] = -1.26615724224333;
   fWeightMatrix0to1[7][10] = -0.0857110580519922;
   fWeightMatrix0to1[8][10] = -1.33581465327637;
   fWeightMatrix0to1[9][10] = -1.66808688569759;
   fWeightMatrix0to1[10][10] = 1.32536137791299;
   fWeightMatrix0to1[11][10] = -0.0274212029417224;
   fWeightMatrix0to1[12][10] = -1.87016317371875;
   fWeightMatrix0to1[13][10] = -1.18357455826596;
   fWeightMatrix0to1[14][10] = 6.93721821118969;
   fWeightMatrix0to1[15][10] = -0.464634856673695;
   fWeightMatrix0to1[16][10] = 0.148607482825874;
   fWeightMatrix0to1[17][10] = 0.0318297202326791;
   fWeightMatrix0to1[18][10] = -6.77642836358739;
   fWeightMatrix0to1[19][10] = -0.747487824736402;
   fWeightMatrix0to1[20][10] = -3.53118894291523;
   fWeightMatrix0to1[21][10] = -1.12777304868292;
   fWeightMatrix0to1[0][11] = -0.850247697075068;
   fWeightMatrix0to1[1][11] = -0.152705018445123;
   fWeightMatrix0to1[2][11] = -0.131890025074565;
   fWeightMatrix0to1[3][11] = 2.41530233308248;
   fWeightMatrix0to1[4][11] = -0.620932062422463;
   fWeightMatrix0to1[5][11] = 0.0195869807328738;
   fWeightMatrix0to1[6][11] = -0.826270721102532;
   fWeightMatrix0to1[7][11] = -0.671246021321333;
   fWeightMatrix0to1[8][11] = 0.688762112385688;
   fWeightMatrix0to1[9][11] = -0.571346530724847;
   fWeightMatrix0to1[10][11] = 2.59922596406243;
   fWeightMatrix0to1[11][11] = 1.0889752692247;
   fWeightMatrix0to1[12][11] = 0.224103977018805;
   fWeightMatrix0to1[13][11] = -0.829790789342765;
   fWeightMatrix0to1[14][11] = -1.96519730273242;
   fWeightMatrix0to1[15][11] = 0.123327612681052;
   fWeightMatrix0to1[16][11] = -0.334993114914259;
   fWeightMatrix0to1[17][11] = 0.759696494611987;
   fWeightMatrix0to1[18][11] = -0.698723256514464;
   fWeightMatrix0to1[19][11] = 0.33673875103246;
   fWeightMatrix0to1[20][11] = 0.0674869025674156;
   fWeightMatrix0to1[21][11] = -0.432994998408628;
   fWeightMatrix0to1[0][12] = 1.08686631735872;
   fWeightMatrix0to1[1][12] = -0.163302321110449;
   fWeightMatrix0to1[2][12] = 0.777362738936792;
   fWeightMatrix0to1[3][12] = -0.357483853871165;
   fWeightMatrix0to1[4][12] = -0.320286172825567;
   fWeightMatrix0to1[5][12] = 0.213858613774147;
   fWeightMatrix0to1[6][12] = -0.991722117421156;
   fWeightMatrix0to1[7][12] = 1.03349076914641;
   fWeightMatrix0to1[8][12] = 1.35277606187189;
   fWeightMatrix0to1[9][12] = -0.0179138453041496;
   fWeightMatrix0to1[10][12] = -0.13258343481862;
   fWeightMatrix0to1[11][12] = -0.401019454582076;
   fWeightMatrix0to1[12][12] = 1.19383384470446;
   fWeightMatrix0to1[13][12] = 0.991252567974657;
   fWeightMatrix0to1[14][12] = 1.24044865880238;
   fWeightMatrix0to1[15][12] = 0.251654868878903;
   fWeightMatrix0to1[16][12] = -1.40838267219409;
   fWeightMatrix0to1[17][12] = 0.580185404552868;
   fWeightMatrix0to1[18][12] = -0.304938432083012;
   fWeightMatrix0to1[19][12] = 0.00764523009321278;
   fWeightMatrix0to1[20][12] = -0.0948193361632666;
   fWeightMatrix0to1[21][12] = -1.48680120748772;
   fWeightMatrix0to1[0][13] = -0.157747441353863;
   fWeightMatrix0to1[1][13] = 0.669706812091046;
   fWeightMatrix0to1[2][13] = -1.47274816362305;
   fWeightMatrix0to1[3][13] = 1.07204531227772;
   fWeightMatrix0to1[4][13] = -0.793270910456703;
   fWeightMatrix0to1[5][13] = -0.228839814957362;
   fWeightMatrix0to1[6][13] = -0.791999222729769;
   fWeightMatrix0to1[7][13] = 0.789955025764057;
   fWeightMatrix0to1[8][13] = -0.173485279058916;
   fWeightMatrix0to1[9][13] = 0.454186942369438;
   fWeightMatrix0to1[10][13] = 0.133057031704281;
   fWeightMatrix0to1[11][13] = 0.46967872487409;
   fWeightMatrix0to1[12][13] = -0.528091059578289;
   fWeightMatrix0to1[13][13] = -1.49320720081509;
   fWeightMatrix0to1[14][13] = -0.821198795747317;
   fWeightMatrix0to1[15][13] = -0.397279096337542;
   fWeightMatrix0to1[16][13] = 0.456736735345415;
   fWeightMatrix0to1[17][13] = 0.18001591866525;
   fWeightMatrix0to1[18][13] = -0.0526740247042973;
   fWeightMatrix0to1[19][13] = 0.0123050986814053;
   fWeightMatrix0to1[20][13] = 0.268091237373582;
   fWeightMatrix0to1[21][13] = -2.59725908230876;
   fWeightMatrix0to1[0][14] = -0.281480684133092;
   fWeightMatrix0to1[1][14] = -3.09315664857687;
   fWeightMatrix0to1[2][14] = 1.32657263386214;
   fWeightMatrix0to1[3][14] = -2.50161246664563;
   fWeightMatrix0to1[4][14] = -2.95292288759445;
   fWeightMatrix0to1[5][14] = 0.345008106851397;
   fWeightMatrix0to1[6][14] = 0.507999972712193;
   fWeightMatrix0to1[7][14] = -0.0868313229972763;
   fWeightMatrix0to1[8][14] = 1.55347675561843;
   fWeightMatrix0to1[9][14] = -3.1912339975882;
   fWeightMatrix0to1[10][14] = 1.12435241886498;
   fWeightMatrix0to1[11][14] = -1.88543912567839;
   fWeightMatrix0to1[12][14] = 5.15737161772934;
   fWeightMatrix0to1[13][14] = -0.772024081061118;
   fWeightMatrix0to1[14][14] = 2.66932864444346;
   fWeightMatrix0to1[15][14] = 0.340430263309096;
   fWeightMatrix0to1[16][14] = -0.827865860602391;
   fWeightMatrix0to1[17][14] = 2.42869307339751;
   fWeightMatrix0to1[18][14] = 5.9114124058422;
   fWeightMatrix0to1[19][14] = 0.315191073952381;
   fWeightMatrix0to1[20][14] = -3.67794823306008;
   fWeightMatrix0to1[21][14] = 1.38581013445482;
   fWeightMatrix0to1[0][15] = -1.37817473778821;
   fWeightMatrix0to1[1][15] = 2.39152019042234;
   fWeightMatrix0to1[2][15] = -1.07823921608419;
   fWeightMatrix0to1[3][15] = -9.19284294965932;
   fWeightMatrix0to1[4][15] = 0.173221664949461;
   fWeightMatrix0to1[5][15] = 8.5550077315912;
   fWeightMatrix0to1[6][15] = 4.91849025687706;
   fWeightMatrix0to1[7][15] = 1.22242709281446;
   fWeightMatrix0to1[8][15] = 0.233259976927998;
   fWeightMatrix0to1[9][15] = -0.475960983325831;
   fWeightMatrix0to1[10][15] = -1.55367472077705;
   fWeightMatrix0to1[11][15] = 1.00885150961368;
   fWeightMatrix0to1[12][15] = -0.80339057872822;
   fWeightMatrix0to1[13][15] = -1.64675444828051;
   fWeightMatrix0to1[14][15] = -0.870788084992514;
   fWeightMatrix0to1[15][15] = -4.53563123325843;
   fWeightMatrix0to1[16][15] = -1.42643341162314;
   fWeightMatrix0to1[17][15] = 0.621045558593616;
   fWeightMatrix0to1[18][15] = -4.65231233975174;
   fWeightMatrix0to1[19][15] = -1.5550607254063;
   fWeightMatrix0to1[20][15] = 10.3518775793476;
   fWeightMatrix0to1[21][15] = 2.15355227075688;
   fWeightMatrix0to1[0][16] = -1.44738169967813;
   fWeightMatrix0to1[1][16] = 0.456378881484565;
   fWeightMatrix0to1[2][16] = 0.255646844748034;
   fWeightMatrix0to1[3][16] = -4.13758151894613;
   fWeightMatrix0to1[4][16] = -4.19699928474382;
   fWeightMatrix0to1[5][16] = -1.08753703527093;
   fWeightMatrix0to1[6][16] = -1.0551721416003;
   fWeightMatrix0to1[7][16] = -1.10866141484039;
   fWeightMatrix0to1[8][16] = 0.200332958052632;
   fWeightMatrix0to1[9][16] = -1.74834673631918;
   fWeightMatrix0to1[10][16] = -1.24250454008436;
   fWeightMatrix0to1[11][16] = -8.70106939630757;
   fWeightMatrix0to1[12][16] = 2.91062030132649;
   fWeightMatrix0to1[13][16] = -1.35917914557796;
   fWeightMatrix0to1[14][16] = -2.1092921586913;
   fWeightMatrix0to1[15][16] = -1.17877863065742;
   fWeightMatrix0to1[16][16] = 1.19210098578718;
   fWeightMatrix0to1[17][16] = -1.44109558473044;
   fWeightMatrix0to1[18][16] = -0.499719403236582;
   fWeightMatrix0to1[19][16] = 0.261242470844663;
   fWeightMatrix0to1[20][16] = -0.0493811516141667;
   fWeightMatrix0to1[21][16] = 1.9835641712415;
   fWeightMatrix0to1[0][17] = 2.14031957399601;
   fWeightMatrix0to1[1][17] = 2.35093347981149;
   fWeightMatrix0to1[2][17] = -0.0949725620465326;
   fWeightMatrix0to1[3][17] = -0.987923285027968;
   fWeightMatrix0to1[4][17] = -1.05075871484869;
   fWeightMatrix0to1[5][17] = 10.4837299983852;
   fWeightMatrix0to1[6][17] = 1.72441393434628;
   fWeightMatrix0to1[7][17] = -0.856693238788554;
   fWeightMatrix0to1[8][17] = -1.56819237572721;
   fWeightMatrix0to1[9][17] = 0.995212274718281;
   fWeightMatrix0to1[10][17] = 0.79460487656968;
   fWeightMatrix0to1[11][17] = 4.29117733783412;
   fWeightMatrix0to1[12][17] = -1.38896781629975;
   fWeightMatrix0to1[13][17] = 1.03263404341461;
   fWeightMatrix0to1[14][17] = -0.0598957097315598;
   fWeightMatrix0to1[15][17] = -3.54537488844473;
   fWeightMatrix0to1[16][17] = -0.919031980095921;
   fWeightMatrix0to1[17][17] = 0.125970908033884;
   fWeightMatrix0to1[18][17] = -7.89485964837044;
   fWeightMatrix0to1[19][17] = -2.18914651615909;
   fWeightMatrix0to1[20][17] = 6.9383883067008;
   fWeightMatrix0to1[21][17] = 0.973723878527926;
   // weight matrix from layer 1 to 2
   fWeightMatrix1to2[0][0] = 0.751803112682993;
   fWeightMatrix1to2[0][1] = 0.662881177996038;
   fWeightMatrix1to2[0][2] = 2.1885301570903;
   fWeightMatrix1to2[0][3] = -1.22025901176782;
   fWeightMatrix1to2[0][4] = 1.42757468417686;
   fWeightMatrix1to2[0][5] = 5.05124930991601;
   fWeightMatrix1to2[0][6] = 0.764033105572003;
   fWeightMatrix1to2[0][7] = -0.388378047760453;
   fWeightMatrix1to2[0][8] = 2.15079079324289;
   fWeightMatrix1to2[0][9] = -0.752295271123878;
   fWeightMatrix1to2[0][10] = -0.616368696089583;
   fWeightMatrix1to2[0][11] = 0.930511698260539;
   fWeightMatrix1to2[0][12] = -0.927334733246001;
   fWeightMatrix1to2[0][13] = -2.03404006771625;
   fWeightMatrix1to2[0][14] = -0.546614336228323;
   fWeightMatrix1to2[0][15] = -2.49312556010478;
   fWeightMatrix1to2[0][16] = 2.76910067576308;
   fWeightMatrix1to2[0][17] = -0.955249978987352;
   fWeightMatrix1to2[0][18] = -1.31292376725801;
   fWeightMatrix1to2[0][19] = -1.16983181218542;
   fWeightMatrix1to2[0][20] = 1.72221806129718;
   fWeightMatrix1to2[0][21] = 0.173501146286768;
   fWeightMatrix1to2[0][22] = 0.431515992620977;
}

inline double ReadMLP_3::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   if (inputValues.size() != (unsigned int)fLayerSize[0]-1) {
      std::cout << "Input vector needs to be of size " << fLayerSize[0]-1 << std::endl;
      return 0;
   }

   for (int l=0; l<fLayers; l++)
      for (int i=0; i<fLayerSize[l]; i++) fWeights[l][i]=0;

   for (int l=0; l<fLayers-1; l++)
      fWeights[l][fLayerSize[l]-1]=1;

   for (int i=0; i<fLayerSize[0]-1; i++)
      fWeights[0][i]=inputValues[i];

   // layer 0 to 1
   for (int o=0; o<fLayerSize[1]-1; o++) {
      for (int i=0; i<fLayerSize[0]; i++) {
         double inputVal = fWeightMatrix0to1[o][i] * fWeights[0][i];
         fWeights[1][o] += inputVal;
      }
      fWeights[1][o] = ActivationFnc(fWeights[1][o]);
   }
   // layer 1 to 2
   for (int o=0; o<fLayerSize[2]; o++) {
      for (int i=0; i<fLayerSize[1]; i++) {
         double inputVal = fWeightMatrix1to2[o][i] * fWeights[1][i];
         fWeights[2][o] += inputVal;
      }
      fWeights[2][o] = OutputActivationFnc(fWeights[2][o]);
   }

   return fWeights[2][0];
}

double ReadMLP_3::ActivationFnc(double x) const {
   // hyperbolic tan
   return tanh(x);
}
double ReadMLP_3::OutputActivationFnc(double x) const {
   // sigmoid
   return 1.0/(1.0+exp(-x));
}
   
// Clean up
inline void ReadMLP_3::Clear() 
{
   // clean up the arrays
   for (int lIdx = 0; lIdx < 3; lIdx++) {
      delete[] fWeights[lIdx];
   }
}
   inline double ReadMLP_3::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            Transform( iV, -1 );
            retval = GetMvaValue__( iV );
         }
         else {
            std::vector<double> iV;
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(*varIt);
            }
            Transform( iV, -1 );
            retval = GetMvaValue__( iV );
         }
      }

      return retval;
   }

//_______________________________________________________________________
inline void ReadMLP_3::InitTransform_1()
{
   // Normalization transformation, initialisation
   fMin_1[0][0] = 3;
   fMax_1[0][0] = 21;
   fMin_1[1][0] = 3;
   fMax_1[1][0] = 19;
   fMin_1[2][0] = 3;
   fMax_1[2][0] = 21;
   fMin_1[0][1] = 2;
   fMax_1[0][1] = 21;
   fMin_1[1][1] = 1;
   fMax_1[1][1] = 26;
   fMin_1[2][1] = 1;
   fMax_1[2][1] = 26;
   fMin_1[0][2] = 1.0816569862e-08;
   fMax_1[0][2] = 96.2506790161;
   fMin_1[1][2] = 4.60151944326e-10;
   fMax_1[1][2] = 103.770103455;
   fMin_1[2][2] = 4.60151944326e-10;
   fMax_1[2][2] = 103.770103455;
   fMin_1[0][3] = -1;
   fMax_1[0][3] = 37;
   fMin_1[1][3] = -1;
   fMax_1[1][3] = 33;
   fMin_1[2][3] = -1;
   fMax_1[2][3] = 37;
   fMin_1[0][4] = 10;
   fMax_1[0][4] = 14;
   fMin_1[1][4] = 10;
   fMax_1[1][4] = 13;
   fMin_1[2][4] = 10;
   fMax_1[2][4] = 14;
   fMin_1[0][5] = 5;
   fMax_1[0][5] = 12;
   fMin_1[1][5] = 0;
   fMax_1[1][5] = 12;
   fMin_1[2][5] = 0;
   fMax_1[2][5] = 12;
   fMin_1[0][6] = 0.0101307211444;
   fMax_1[0][6] = 40.2817649841;
   fMin_1[1][6] = 0.00728893233463;
   fMax_1[1][6] = 42.1457099915;
   fMin_1[2][6] = 0.00728893233463;
   fMax_1[2][6] = 42.1457099915;
   fMin_1[0][7] = 3;
   fMax_1[0][7] = 9;
   fMin_1[1][7] = 3;
   fMax_1[1][7] = 8;
   fMin_1[2][7] = 3;
   fMax_1[2][7] = 9;
   fMin_1[0][8] = 0;
   fMax_1[0][8] = 8;
   fMin_1[1][8] = 0;
   fMax_1[1][8] = 7;
   fMin_1[2][8] = 0;
   fMax_1[2][8] = 8;
   fMin_1[0][9] = 0;
   fMax_1[0][9] = 8;
   fMin_1[1][9] = 0;
   fMax_1[1][9] = 8;
   fMin_1[2][9] = 0;
   fMax_1[2][9] = 8;
   fMin_1[0][10] = 0.0505929067731;
   fMax_1[0][10] = 87.7711715698;
   fMin_1[1][10] = 0.0516117885709;
   fMax_1[1][10] = 105.047515869;
   fMin_1[2][10] = 0.0505929067731;
   fMax_1[2][10] = 105.047515869;
   fMin_1[0][11] = 0;
   fMax_1[0][11] = 2;
   fMin_1[1][11] = 0;
   fMax_1[1][11] = 2;
   fMin_1[2][11] = 0;
   fMax_1[2][11] = 2;
   fMin_1[0][12] = 223;
   fMax_1[0][12] = 6680;
   fMin_1[1][12] = 356;
   fMax_1[1][12] = 6680;
   fMin_1[2][12] = 223;
   fMax_1[2][12] = 6680;
   fMin_1[0][13] = 143;
   fMax_1[0][13] = 4409;
   fMin_1[1][13] = 196;
   fMax_1[1][13] = 4409;
   fMin_1[2][13] = 143;
   fMax_1[2][13] = 4409;
   fMin_1[0][14] = 0.845625579357;
   fMax_1[0][14] = 123.966957092;
   fMin_1[1][14] = 0.5633071661;
   fMax_1[1][14] = 128.49848938;
   fMin_1[2][14] = 0.5633071661;
   fMax_1[2][14] = 128.49848938;
   fMin_1[0][15] = 22.8750095367;
   fMax_1[0][15] = 25693.4316406;
   fMin_1[1][15] = 12.2846269608;
   fMax_1[1][15] = 127576.226562;
   fMin_1[2][15] = 12.2846269608;
   fMax_1[2][15] = 127576.226562;
   fMin_1[0][16] = 1.52242255211;
   fMax_1[0][16] = 6.45639371872;
   fMin_1[1][16] = 1.54100084305;
   fMax_1[1][16] = 6.96952486038;
   fMin_1[2][16] = 1.52242255211;
   fMax_1[2][16] = 6.96952486038;
}

//_______________________________________________________________________
inline void ReadMLP_3::Transform_1( std::vector<double>& iv, int cls) const
{
   // Normalization transformation
   if (cls < 0 || cls > 2) {
   if (2 > 1 ) cls = 2;
      else cls = 2;
   }
   const int nVar = 17;

   // get indices of used variables

   // define the indices of the variables which are transformed by this transformation
   static std::vector<int> indicesGet;
   static std::vector<int> indicesPut;

   if ( indicesGet.empty() ) { 
      indicesGet.reserve(fNvars);
      indicesGet.push_back( 0);
      indicesGet.push_back( 1);
      indicesGet.push_back( 2);
      indicesGet.push_back( 3);
      indicesGet.push_back( 4);
      indicesGet.push_back( 5);
      indicesGet.push_back( 6);
      indicesGet.push_back( 7);
      indicesGet.push_back( 8);
      indicesGet.push_back( 9);
      indicesGet.push_back( 10);
      indicesGet.push_back( 11);
      indicesGet.push_back( 12);
      indicesGet.push_back( 13);
      indicesGet.push_back( 14);
      indicesGet.push_back( 15);
      indicesGet.push_back( 16);
   } 
   if ( indicesPut.empty() ) { 
      indicesPut.reserve(fNvars);
      indicesPut.push_back( 0);
      indicesPut.push_back( 1);
      indicesPut.push_back( 2);
      indicesPut.push_back( 3);
      indicesPut.push_back( 4);
      indicesPut.push_back( 5);
      indicesPut.push_back( 6);
      indicesPut.push_back( 7);
      indicesPut.push_back( 8);
      indicesPut.push_back( 9);
      indicesPut.push_back( 10);
      indicesPut.push_back( 11);
      indicesPut.push_back( 12);
      indicesPut.push_back( 13);
      indicesPut.push_back( 14);
      indicesPut.push_back( 15);
      indicesPut.push_back( 16);
   } 

   static std::vector<double> dv;
   dv.resize(nVar);
   for (int ivar=0; ivar<nVar; ivar++) dv[ivar] = iv[indicesGet.at(ivar)];
   for (int ivar=0;ivar<17;ivar++) {
      double offset = fMin_1[cls][ivar];
      double scale  = 1.0/(fMax_1[cls][ivar]-fMin_1[cls][ivar]);
      iv[indicesPut.at(ivar)] = (dv[ivar]-offset)*scale * 2 - 1;
   }
}

//_______________________________________________________________________
inline void ReadMLP_3::InitTransform()
{
   InitTransform_1();
}

//_______________________________________________________________________
inline void ReadMLP_3::Transform( std::vector<double>& iv, int sigOrBgd ) const
{
   Transform_1( iv, sigOrBgd );
}
